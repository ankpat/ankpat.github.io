
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>NeuralNetwork Package &#8212; Neural Network 1.0 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Homework 5" href="homework5.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="neuralnetwork-package">
<h1>NeuralNetwork Package<a class="headerlink" href="#neuralnetwork-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-NeuralNetwork">
<span id="package-contents"></span><h2>Package contents<a class="headerlink" href="#module-NeuralNetwork" title="Permalink to this headline">¶</a></h2>
<p>This is a pure Python implementation of a Feed Forward/Back-Propagation Neural Network.</p>
<p>A Neural Network consists of Layers of Perceptrons. A Perceptron is a single logical unit
which takes input and computes an output by some activity and activation function.</p>
<p>A Layer consists of one or more Perceptrons. All Perceptrons in a layer receive the same inputs
and the outputs are then aggregated into a vector and sent as inputs to the next layer. A special
case is made for the final layer with a single Perceptron, as it is typically referred to as the
output layer.</p>
<p>A Neural Network in this instance consists of one or more Layers. A Neural Network receives one or
more inputs and produces a single output. A Neural Network can be trained using the Feed-Forward/
Back-Propagation method which attempts to find the global minimum of the Mean Squared Error.</p>
</div>
<div class="section" id="module-NeuralNetwork.Perceptron">
<span id="perceptron"></span><h2>Perceptron<a class="headerlink" href="#module-NeuralNetwork.Perceptron" title="Permalink to this headline">¶</a></h2>
<p>The Perceptron is the most basic unit of a Neural Network.</p>
<p>The Perceptron provides a mapping from <span class="math">\(\mathbb{R}^n\rightarrow\mathbb{R}\)</span> by using
a linear basis function for the activity function and a signmoid function for the activation
function.</p>
<p>Given a set of inputs <span class="math">\(\{x_1, x_2, \ldots, x_n\}\)</span>, a set of weights
<span class="math">\(\{w_1, w_2, \ldots, w_n\}\)</span>, and a bias <span class="math">\(\theta\)</span>:</p>
<p>The Activity value is computed as the weighted sum of all of the inputs to the Perceptron
plus a Bias:</p>
<div class="math">
\[y = \sum_{i=1}^{n} w_i x_i + \theta\]</div>
<p>The Activation value is computed using the Sigmoid function with the activity value as the
parameter.</p>
<div class="math">
\[v = \frac{1}{1+e^{-y}}\]</div>
<dl class="class">
<dt id="NeuralNetwork.Perceptron.Perceptron">
<em class="property">class </em><code class="descclassname">NeuralNetwork.Perceptron.</code><code class="descname">Perceptron</code><span class="sig-paren">(</span><em>number_of_inputs: int, weights: typing.List[float], bias: float</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/NeuralNetwork/Perceptron.html#Perceptron"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#NeuralNetwork.Perceptron.Perceptron" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>A perceptron takes inputs and computes an activity value based on the inputs
and specified weights and bias.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>number_of_inputs</strong> (<em>int</em>) – Used soley for sanity checking length of weights list</li>
<li><strong>weights</strong> (<em>WEIGHTS</em>) – A list of weights for each input</li>
<li><strong>bias</strong> (<em>float</em>) – A constant value added to the the weighted sum of inputs</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="NeuralNetwork.Perceptron.Perceptron.activation">
<code class="descname">activation</code><span class="sig-paren">(</span><em>inputs: typing.List[float]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/NeuralNetwork/Perceptron.html#Perceptron.activation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#NeuralNetwork.Perceptron.Perceptron.activation" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the value of the activation function</p>
<p>The activation function is computed as the sigmoid function with the activity
function as its parameter.</p>
<div class="math">
\[v = \frac{1}{1+e^{-y}}\]</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>inputs</strong> (<em>Inputs</em>) – A list of input values</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Computed value of the activation function</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="NeuralNetwork.Perceptron.Perceptron.activity">
<code class="descname">activity</code><span class="sig-paren">(</span><em>inputs: typing.List[float]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/NeuralNetwork/Perceptron.html#Perceptron.activity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#NeuralNetwork.Perceptron.Perceptron.activity" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the value of the activity function.</p>
<p>The activity function is computed as the weighted sum of all inputs plus the bias</p>
<div class="math">
\[y = \sum_{i=1}^{n} w_i x_i + \theta\]</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>inputs</strong> (<em>Inputs</em>) – A list of input values</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Computed value of activity function</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="NeuralNetwork.Perceptron.Perceptron.adjust_weights">
<code class="descname">adjust_weights</code><span class="sig-paren">(</span><em>delta: typing.List[float]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/NeuralNetwork/Perceptron.html#Perceptron.adjust_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#NeuralNetwork.Perceptron.Perceptron.adjust_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Adjust weights of Perceptron by some given factor</p>
<p>Given a list of deltas, <span class="math">\(\{\delta_1, \delta_2, \ldots, \delta_m\}, m \geq n\)</span>, the new
weights are calculated as <span class="math">\(w_i + \delta_i\)</span>. If m = n+1, then the bias is updated.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>delta</strong> (<em>WEIGHTS</em>) – A list of delta values for each of the weights.
There must be one delta for each weight. An additional delta can be specified to
update the bias.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">None</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="NeuralNetwork.Perceptron.Perceptron.bias">
<code class="descname">bias</code><a class="headerlink" href="#NeuralNetwork.Perceptron.Perceptron.bias" title="Permalink to this definition">¶</a></dt>
<dd><p><em>float</em> – The bias associated with this Perceptron</p>
</dd></dl>

<dl class="attribute">
<dt id="NeuralNetwork.Perceptron.Perceptron.number_of_inputs">
<code class="descname">number_of_inputs</code><a class="headerlink" href="#NeuralNetwork.Perceptron.Perceptron.number_of_inputs" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – Number of inputs expected by this Perceptron</p>
</dd></dl>

<dl class="attribute">
<dt id="NeuralNetwork.Perceptron.Perceptron.weights">
<code class="descname">weights</code><a class="headerlink" href="#NeuralNetwork.Perceptron.Perceptron.weights" title="Permalink to this definition">¶</a></dt>
<dd><p><em>WEIGHTS</em> – The weights associated with this Perceptron</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-NeuralNetwork.Layer">
<span id="layer"></span><h2>Layer<a class="headerlink" href="#module-NeuralNetwork.Layer" title="Permalink to this headline">¶</a></h2>
<p>Neural Network Layer of Perceptrons.</p>
<dl class="class">
<dt id="NeuralNetwork.Layer.Layer">
<em class="property">class </em><code class="descclassname">NeuralNetwork.Layer.</code><code class="descname">Layer</code><span class="sig-paren">(</span><em>number_of_nodes: int, number_of_inputs: int, weights: typing.List[float], bias: float</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/NeuralNetwork/Layer.html#Layer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#NeuralNetwork.Layer.Layer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>A Layer consists of one or more Perceptrons that are all given the same set of inputs.
The outputs of all Perceptrons in the layer are returned as a single vector.</p>
<dl class="method">
<dt id="NeuralNetwork.Layer.Layer.feed">
<code class="descname">feed</code><span class="sig-paren">(</span><em>inputs: typing.List[float]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/NeuralNetwork/Layer.html#Layer.feed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#NeuralNetwork.Layer.Layer.feed" title="Permalink to this definition">¶</a></dt>
<dd><p>Feed inputs through the layer and return list of outputs</p>
<p>Input are fed to all nodes in the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>inputs</strong> (<em>INPUTS</em>) – A list of input values</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">List[float] A list containing the output of each node in this layer</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="classmethod">
<dt id="NeuralNetwork.Layer.Layer.make_layer">
<em class="property">classmethod </em><code class="descname">make_layer</code><span class="sig-paren">(</span><em>perceptrons: typing.List[NeuralNetwork.Perceptron.Perceptron]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/NeuralNetwork/Layer.html#Layer.make_layer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#NeuralNetwork.Layer.Layer.make_layer" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a new layer from existing Perceptrons</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>perceptrons</strong> (<em>LAYER</em>) – A list defining all perceptrons within this layer</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">An initialized Layer object</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#module-NeuralNetwork.Layer" title="NeuralNetwork.Layer">Layer</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-NeuralNetwork.Network">
<span id="network"></span><h2>Network<a class="headerlink" href="#module-NeuralNetwork.Network" title="Permalink to this headline">¶</a></h2>
<p>Neural Network Implementation</p>
<dl class="class">
<dt id="NeuralNetwork.Network.Network">
<em class="property">class </em><code class="descclassname">NeuralNetwork.Network.</code><code class="descname">Network</code><span class="sig-paren">(</span><em>layers: typing.List[NeuralNetwork.Layer.Layer]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/NeuralNetwork/Network.html#Network"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#NeuralNetwork.Network.Network" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>A Neural Network consists of one or more Layer objects containing Perceptrons. A Neural
Network receives one or more inputs and produces a single output.
This implementation can be trained using the Feed-Forward/Back-Propagation method which
attempts to find the global minimum of the Mean Squared Error.</p>
<p>Mathematically, this Neural Network is a mapping <span class="math">\(\mathbb{R}^n \rightarrow \mathbb{R}\)</span>.</p>
<dl class="method">
<dt id="NeuralNetwork.Network.Network.feed">
<code class="descname">feed</code><span class="sig-paren">(</span><em>inputs: typing.List[float], desired: typing.Union[float, NoneType] = None</em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="_modules/NeuralNetwork/Network.html#Network.feed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#NeuralNetwork.Network.Network.feed" title="Permalink to this definition">¶</a></dt>
<dd><p>Feed inputs to the network and return single output.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>inputs</strong> (<em>INPUTS</em>) – A list of inputs given to this Neural Network</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The final value returned by the output layer.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">float</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="NeuralNetwork.Network.Network.to_dot">
<code class="descname">to_dot</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/NeuralNetwork/Network.html#Network.to_dot"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#NeuralNetwork.Network.Network.to_dot" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a string representation of this Neural Network in graphviz DOT format</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">DOT representation</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">str</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="NeuralNetwork.Network.Network.train">
<code class="descname">train</code><span class="sig-paren">(</span><em>inputs: typing.List[float], desired: float, gain_factor: float = 1.0, iterations: int = 15, train_bias=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/NeuralNetwork/Network.html#Network.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#NeuralNetwork.Network.Network.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a neural network with a single Input/Ouput pair</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>inputs</strong> (<em>INPUTS</em>) – Training data for the Neural Network</li>
<li><strong>desired</strong> (<em>float</em>) – The expected output</li>
<li><strong>gain_factor</strong> (<em>float</em>) – The factor by which each successive weight
term is shifted each iteration.</li>
<li><strong>iterations</strong> (<em>int</em>) – The number of iterations of training to perform</li>
<li><strong>train_bias</strong> (<em>bool</em>) – Flag to incorporate training of the Bias. Disabled by default.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="NeuralNetwork.Network.Network.train_alternating">
<code class="descname">train_alternating</code><span class="sig-paren">(</span><em>inputs: typing.List[typing.List[float]], desired: typing.List[float], gain_factor: float, iterations: int, train_bias: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/NeuralNetwork/Network.html#Network.train_alternating"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#NeuralNetwork.Network.Network.train_alternating" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a neural network with multiple input/output pairs.</p>
<p>Alternating training means that the input/output pairs will be used one after the other
for the specified number of iterations. Given a set of inputs (I1, I2, I3…) and
outputs (O1, O2, O3), the Neural Network will be trained on (I1, O1), (I2,O2), (I3, O3)
for every of the specified iterations.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>inputs</strong> (<em>List</em><em>[</em><em>INPUTS</em><em>]</em>) – A list of training data for the Neural Network</li>
<li><strong>desired</strong> (<em>List</em><em>[</em><em>float</em><em>]</em>) – The expected outputs for each input set</li>
<li><strong>gain_factor</strong> (<em>float</em>) – The factor by which each successive weight
term is shifted each iteration.</li>
<li><strong>iterations</strong> (<em>int</em>) – The number of iterations of training to perform</li>
<li><strong>train_bias</strong> (<em>bool</em>) – Flag to incorporate training of the Bias. Disabled by default.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="NeuralNetwork.Network.Network.train_round">
<code class="descname">train_round</code><span class="sig-paren">(</span><em>inputs: typing.List[float], desired: float, gain_factor: float, train_bias: bool = False</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/NeuralNetwork/Network.html#Network.train_round"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#NeuralNetwork.Network.Network.train_round" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform a single round of the Feed-Forward/Back-Propagation (FFBP) algorithm to train
a Neural Network.</p>
<p>The FFBP algorithm as two phases as the name implies.</p>
<ol class="arabic">
<li><p class="first">In the Feed-Forward phase, the inputs are fed through the Neural Network as is
and the final output value is used to compute the error and the squared error.</p>
<p>The Neural Network maps <span class="math">\(\mathbb{R}^n \rightarrow \mathbb{R}\)</span>. The input is a
vector of real numbers and the output is a single real number. The difference between
the actual output value and the expected output for a given set of inputs is the Error
<span class="math">\(e\)</span>. The Mean Square Error, <span class="math">\(E = \frac{1}{2} e^2\)</span> is minimized using the
Perceptron Delta Rule.</p>
</li>
<li><p class="first">In the Back-Propagation phase, the error values are then used to calculate changes in
the weights for each layer of the Neural Network.</p>
<p>This delta value is then propagated back through the Neural Network’s hidden layers to
update the weights of hidden layer perceptrons. Deltas are propagated backwards through
the Neural Network until the weights of the first layer have been updated.</p>
<p>Then the training process can either continue for another round or can terminate.</p>
</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>inputs</strong> (<em>INPUTS</em>) – A list of input values.</li>
<li><strong>desired</strong> (<em>float</em>) – The expected output value of this Neural Network for the given input.</li>
<li><strong>gain_factor</strong> (<em>float</em>) – The factor by which each successive weight
term is shifted each iteration.</li>
<li><strong>train_bias</strong> (<em>bool</em>) – Flag to incorporate training of the Bias.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="NeuralNetwork.Network.Network.train_successive">
<code class="descname">train_successive</code><span class="sig-paren">(</span><em>inputs: typing.List[typing.List[float]], desired: typing.List[float], gain_factor: float, iterations: int, train_bias: bool = False</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/NeuralNetwork/Network.html#Network.train_successive"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#NeuralNetwork.Network.Network.train_successive" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a neural network with multiple input/output pairs.</p>
<p>Successive training means that the input/output pairs will be used
one at a time to train the neural network for the specified number of iterations
before moving on to the next input/output pair.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>inputs</strong> (<em>List</em><em>[</em><em>INPUTS</em><em>]</em>) – A list of training data for the Neural Network</li>
<li><strong>desired</strong> (<em>List</em><em>[</em><em>float</em><em>]</em>) – The expected outputs for each input set</li>
<li><strong>gain_factor</strong> (<em>float</em>) – The factor by which each successive weight
term is shifted each iteration.</li>
<li><strong>iterations</strong> (<em>int</em>) – The number of iterations of training to perform for each input</li>
<li><strong>train_bias</strong> (<em>bool</em>) – Flag to incorporate training of the Bias. Disabled by default.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">Neural Network</a></h1>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=ankpat&repo=jhu&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="homework5.html">Homework 5</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">NeuralNetwork Package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-NeuralNetwork">Package contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-NeuralNetwork.Perceptron">Perceptron</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-NeuralNetwork.Layer">Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-NeuralNetwork.Network">Network</a></li>
</ul>
</li>
</ul>


<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Ankit Patel.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="_sources/NeuralNetwork.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>