
Homework 5
==========

.. contents:: Table of Contents
    :depth: 2

For this assignment, create a neural network program using a language of your choice that
implements the feedforward, back propagation algorithm for a network with the following topology
like the one in the lecture:

.. graphviz::

    digraph simple_network {
        rankdir=LR;

        node [shape=plaintext,width=0.25,label=<x<SUB>1</SUB>>]; x_1;
        node [shape=plaintext,width=0.25,label=<x<SUB>2</SUB>>]; x_2;
        node [shape=square,width=.25,fillcolor=black,style=filled,label=""]; input_0, input_1;
        node [shape=circle,width=.5,fillcolor=white,label=""]; h_0_0, h_0_1;
        node [shape=circle,width=.5,fillcolor=white,label=""]; o_0;
        node [shape=circle,width=.5,style=invisible,label=""]; output;


        x_1 -> input_0;
        x_2 -> input_1;
        input_0 -> h_0_0;
        input_1 -> h_0_0;

        input_0 -> h_0_1;
        input_1 -> h_0_1;

        h_0_0 -> o_0;
        h_0_1 -> o_0;

        o_0 -> output [label="Output"];
    }




Testing
-------


Use the example from class to verify that the network performs correctly.

The initial weights for each node of the hidden layer are 0.3 for all inputs and the initial
weights for all inputs to the output layer are 0.8.

The Gain factor :math:`\eta = 1.0` and all biases are set to 0.

The Input {1, 2} should generate a desired output of 0.7.

Biases will not be updated for this run of the training algorithm.



Initial Network
~~~~~~~~~~~~~~~

.. graphviz::

    digraph network{
    rankdir=LR;
    node [shape=plaintext,width=0.25,label=<x<SUB>1</SUB>>]; x_1;
    node [shape=plaintext,width=0.25,label=<x<SUB>2</SUB>>]; x_2;
    node [shape=square,width=.25,fillcolor=black,style=filled,label=""]; input_0, input_1
    node [shape=circle,width=.5,fillcolor=white,label="0.000000"]; h_0_0;
    node [shape=circle,width=.5,fillcolor=white,label="0.000000"]; h_0_1;
    node [shape=circle,width=.5,fillcolor=white,label="0.000000"]; o_0;
    node [shape=circle,width=.5,style=invisible,label=""]; output;
    
    
    x_1 -> input_0;
    x_2 -> input_1;
    input_0 -> h_0_0 [label="0.300000"];
    input_1 -> h_0_0 [label="0.300000"];
    input_0 -> h_0_1 [label="0.300000"];
    input_1 -> h_0_1 [label="0.300000"];
    h_0_0 -> o_0 [label="0.800000"];
    h_0_1 -> o_0 [label="0.800000"];
    o_0 -> output [label="Output"];
    }
    

Iteration 1
~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 2)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.7000000000                0.7572238708              -0.0572238708             0.0016372857                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.7572238708)(1 - 0.2427761292)(-0.0572238708) = -0.0105198007`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.7925209530 = 0.8000000000 + 1.000000(-0.0105198007)(0.7109495026)`

:math:`w_2 = 0.7925209530 = 0.8000000000 + 1.000000(-0.0105198007)(0.7109495026)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0017294578 = (0.7109495026)(0.2890504974)(-0.010520)(0.800000)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.2982705422 = 0.3000000000 + 1.000000(-0.0017294578)(1.0000000000)`

:math:`w_2 = 0.2965410844 = 0.3000000000 + 1.000000(-0.0017294578)(2.0000000000)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0017294578 = (0.7109495026)(0.2890504974)(-0.010520)(0.800000)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.2982705422 = 0.3000000000 + 1.000000(-0.0017294578)(1.0000000000)`

:math:`w_2 = 0.2965410844 = 0.3000000000 + 1.000000(-0.0017294578)(2.0000000000)`

Network After One Training Cycle
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. graphviz::

    digraph network{
    rankdir=LR;
    node [shape=plaintext,width=0.25,label=<x<SUB>1</SUB>>]; x_1;
    node [shape=plaintext,width=0.25,label=<x<SUB>2</SUB>>]; x_2;
    node [shape=square,width=.25,fillcolor=black,style=filled,label=""]; input_0, input_1
    node [shape=circle,width=.5,fillcolor=white,label="0.000000"]; h_0_0;
    node [shape=circle,width=.5,fillcolor=white,label="0.000000"]; h_0_1;
    node [shape=circle,width=.5,fillcolor=white,label="0.000000"]; o_0;
    node [shape=circle,width=.5,style=invisible,label=""]; output;
    
    
    x_1 -> input_0;
    x_2 -> input_1;
    input_0 -> h_0_0 [label="0.298271"];
    input_1 -> h_0_0 [label="0.296541"];
    input_0 -> h_0_1 [label="0.298271"];
    input_1 -> h_0_1 [label="0.296541"];
    h_0_0 -> o_0 [label="0.792521"];
    h_0_1 -> o_0 [label="0.792521"];
    o_0 -> output [label="Output"];
    }
    


Second Feed Forward Epoch
~~~~~~~~~~~~~~~~~~~~~~~~~~~

These are the results after a single round of training as described above.

Feed forward with inputs: (1, 2)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.7000000000                0.7547415782              -0.0547415782             0.0014983202                       
=========================== ========================= ========================= ==================================


Alternating Training Method
---------------------------


For each cycle of this training procedure, present the first input/output pair,
perform the back propagation technique to update the weights, then present the second
input/output pair and again perform the back propagation technique to update the
weights. This constitutes a single cycle.

These are the results of executing 15 iterations of training with this method with the following
inputs:

.. math:: ( 1, 1) \rightarrow 0.9

.. math:: (-1, -1) \rightarrow 0.05


.. contents:: Iterations
    :depth: 1
    :local:


Iteration 1
~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.7375067919              0.1624932081              0.0132020213                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.7375067919)(1 - 0.2624932081)(0.1624932081) = 0.0314571453`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.8203105042 = 0.8000000000 + 1.000000(0.0314571453)(0.6456563062)`

:math:`w_2 = 0.8203105042 = 0.8000000000 + 1.000000(0.0314571453)(0.6456563062)`

:math:`bias = 0.0314571453 = 0.0000000000 + (1.0000000000)(0.0314571453)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0057575193 = (0.6456563062)(0.3543436938)(0.031457)(0.800000)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3057575193 = 0.3000000000 + 1.000000(0.0057575193)(1.0000000000)`

:math:`w_2 = 0.3057575193 = 0.3000000000 + 1.000000(0.0057575193)(1.0000000000)`

:math:`bias = 0.0057575193 = 0.0000000000 + (1.0000000000)(0.0057575193)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0057575193 = (0.6456563062)(0.3543436938)(0.031457)(0.800000)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3057575193 = 0.3000000000 + 1.000000(0.0057575193)(1.0000000000)`

:math:`w_2 = 0.3057575193 = 0.3000000000 + 1.000000(0.0057575193)(1.0000000000)`

:math:`bias = 0.0057575193 = 0.0000000000 + (1.0000000000)(0.0057575193)`

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.6480871448              -0.5980871448             0.1788541164                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.6480871448)(1 - 0.3519128552)(-0.5980871448) = -0.1364058533`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.7721554771 = 0.8203105042 + 1.000000(-0.1364058533)(0.3530275715)`

:math:`w_2 = 0.7721554771 = 0.8203105042 + 1.000000(-0.1364058533)(0.3530275715)`

:math:`bias = -0.1049487080 = 0.0314571453 + (1.0000000000)(-0.1364058533)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0255567531 = (0.3530275715)(0.6469724285)(-0.136406)(0.820311)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3313142724 = 0.3057575193 + 1.000000(-0.0255567531)(-1.0000000000)`

:math:`w_2 = 0.3313142724 = 0.3057575193 + 1.000000(-0.0255567531)(-1.0000000000)`

:math:`bias = -0.0197992338 = 0.0057575193 + (1.0000000000)(-0.0255567531)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0255567531 = (0.3530275715)(0.6469724285)(-0.136406)(0.820311)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3313142724 = 0.3057575193 + 1.000000(-0.0255567531)(-1.0000000000)`

:math:`w_2 = 0.3313142724 = 0.3057575193 + 1.000000(-0.0255567531)(-1.0000000000)`

:math:`bias = -0.0197992338 = 0.0057575193 + (1.0000000000)(-0.0255567531)`

Iteration 2
~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.7124230634              0.1875769366              0.0175925536                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.7124230634)(1 - 0.2875769366)(0.1875769366) = 0.0384300954`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.7973422830 = 0.7721554771 + 1.000000(0.0384300954)(0.6553927499)`

:math:`w_2 = 0.7973422830 = 0.7721554771 + 1.000000(0.0384300954)(0.6553927499)`

:math:`bias = -0.0665186126 = -0.1049487080 + (1.0000000000)(0.0384300954)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0067019666 = (0.6553927499)(0.3446072501)(0.038430)(0.772155)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3380162390 = 0.3313142724 + 1.000000(0.0067019666)(1.0000000000)`

:math:`w_2 = 0.3380162390 = 0.3313142724 + 1.000000(0.0067019666)(1.0000000000)`

:math:`bias = -0.0130972672 = -0.0197992338 + (1.0000000000)(0.0067019666)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0067019666 = (0.6553927499)(0.3446072501)(0.038430)(0.772155)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3380162390 = 0.3313142724 + 1.000000(0.0067019666)(1.0000000000)`

:math:`w_2 = 0.3380162390 = 0.3313142724 + 1.000000(0.0067019666)(1.0000000000)`

:math:`bias = -0.0130972672 = -0.0197992338 + (1.0000000000)(0.0067019666)`

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.6145473298              -0.5645473298             0.1593568438                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.6145473298)(1 - 0.3854526702)(-0.5645473298) = -0.1337293557`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.7526463626 = 0.7973422830 + 1.000000(-0.1337293557)(0.3342266937)`

:math:`w_2 = 0.7526463626 = 0.7973422830 + 1.000000(-0.1337293557)(0.3342266937)`

:math:`bias = -0.2002479683 = -0.0665186126 + (1.0000000000)(-0.1337293557)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0237267939 = (0.3342266937)(0.6657733063)(-0.133729)(0.797342)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3617430330 = 0.3380162390 + 1.000000(-0.0237267939)(-1.0000000000)`

:math:`w_2 = 0.3617430330 = 0.3380162390 + 1.000000(-0.0237267939)(-1.0000000000)`

:math:`bias = -0.0368240612 = -0.0130972672 + (1.0000000000)(-0.0237267939)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0237267939 = (0.3342266937)(0.6657733063)(-0.133729)(0.797342)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3617430330 = 0.3380162390 + 1.000000(-0.0237267939)(-1.0000000000)`

:math:`w_2 = 0.3617430330 = 0.3380162390 + 1.000000(-0.0237267939)(-1.0000000000)`

:math:`bias = -0.0368240612 = -0.0130972672 + (1.0000000000)(-0.0237267939)`

Iteration 3
~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.6902116191              0.2097883809              0.0220055824                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.6902116191)(1 - 0.3097883809)(0.2097883809) = 0.0448568551`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.7824862175 = 0.7526463626 + 1.000000(0.0448568551)(0.6652239622)`

:math:`w_2 = 0.7824862175 = 0.7526463626 + 1.000000(0.0448568551)(0.6652239622)`

:math:`bias = -0.1553911132 = -0.2002479683 + (1.0000000000)(0.0448568551)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0075186876 = (0.6652239622)(0.3347760378)(0.044857)(0.752646)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3692617206 = 0.3617430330 + 1.000000(0.0075186876)(1.0000000000)`

:math:`w_2 = 0.3692617206 = 0.3617430330 + 1.000000(0.0075186876)(1.0000000000)`

:math:`bias = -0.0293053736 = -0.0368240612 + (1.0000000000)(0.0075186876)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0075186876 = (0.6652239622)(0.3347760378)(0.044857)(0.752646)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3692617206 = 0.3617430330 + 1.000000(0.0075186876)(1.0000000000)`

:math:`w_2 = 0.3692617206 = 0.3617430330 + 1.000000(0.0075186876)(1.0000000000)`

:math:`bias = -0.0293053736 = -0.0368240612 + (1.0000000000)(0.0075186876)`

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.5843424027              -0.5343424027             0.1427609017                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.5843424027)(1 - 0.4156575973)(-0.5343424027) = -0.1297844807`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.7413511607 = 0.7824862175 + 1.000000(-0.1297844807)(0.3169489643)`

:math:`w_2 = 0.7413511607 = 0.7824862175 + 1.000000(-0.1297844807)(0.3169489643)`

:math:`bias = -0.2851755939 = -0.1553911132 + (1.0000000000)(-0.1297844807)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0219857837 = (0.3169489643)(0.6830510357)(-0.129784)(0.782486)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3912475043 = 0.3692617206 + 1.000000(-0.0219857837)(-1.0000000000)`

:math:`w_2 = 0.3912475043 = 0.3692617206 + 1.000000(-0.0219857837)(-1.0000000000)`

:math:`bias = -0.0512911573 = -0.0293053736 + (1.0000000000)(-0.0219857837)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0219857837 = (0.3169489643)(0.6830510357)(-0.129784)(0.782486)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3912475043 = 0.3692617206 + 1.000000(-0.0219857837)(-1.0000000000)`

:math:`w_2 = 0.3912475043 = 0.3692617206 + 1.000000(-0.0219857837)(-1.0000000000)`

:math:`bias = -0.0512911573 = -0.0293053736 + (1.0000000000)(-0.0219857837)`

Iteration 4
~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.6716707532              0.2283292468              0.0260671225                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.6716707532)(1 - 0.3283292468)(0.2283292468) = 0.0503532553`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.7753431023 = 0.7413511607 + 1.000000(0.0503532553)(0.6750693938)`

:math:`w_2 = 0.7753431023 = 0.7413511607 + 1.000000(0.0503532553)(0.6750693938)`

:math:`bias = -0.2348223386 = -0.2851755939 + (1.0000000000)(0.0503532553)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0081882400 = (0.6750693938)(0.3249306062)(0.050353)(0.741351)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3994357443 = 0.3912475043 + 1.000000(0.0081882400)(1.0000000000)`

:math:`w_2 = 0.3994357443 = 0.3912475043 + 1.000000(0.0081882400)(1.0000000000)`

:math:`bias = -0.0431029173 = -0.0512911573 + (1.0000000000)(0.0081882400)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0081882400 = (0.6750693938)(0.3249306062)(0.050353)(0.741351)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3994357443 = 0.3912475043 + 1.000000(0.0081882400)(1.0000000000)`

:math:`w_2 = 0.3994357443 = 0.3912475043 + 1.000000(0.0081882400)(1.0000000000)`

:math:`bias = -0.0431029173 = -0.0512911573 + (1.0000000000)(0.0081882400)`

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.5577705761              -0.5077705761             0.1289154790                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.5577705761)(1 - 0.4422294239)(-0.5077705761) = -0.1252479905`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.7376285383 = 0.7753431023 + 1.000000(-0.1252479905)(0.3011191143)`

:math:`w_2 = 0.7376285383 = 0.7753431023 + 1.000000(-0.1252479905)(0.3011191143)`

:math:`bias = -0.3600703291 = -0.2348223386 + (1.0000000000)(-0.1252479905)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0204364841 = (0.3011191143)(0.6988808857)(-0.125248)(0.775343)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4198722284 = 0.3994357443 + 1.000000(-0.0204364841)(-1.0000000000)`

:math:`w_2 = 0.4198722284 = 0.3994357443 + 1.000000(-0.0204364841)(-1.0000000000)`

:math:`bias = -0.0635394014 = -0.0431029173 + (1.0000000000)(-0.0204364841)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0204364841 = (0.3011191143)(0.6988808857)(-0.125248)(0.775343)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4198722284 = 0.3994357443 + 1.000000(-0.0204364841)(-1.0000000000)`

:math:`w_2 = 0.4198722284 = 0.3994357443 + 1.000000(-0.0204364841)(-1.0000000000)`

:math:`bias = -0.0635394014 = -0.0431029173 + (1.0000000000)(-0.0204364841)`

Iteration 5
~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.6570728031              0.2429271969              0.0295068115                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.6570728031)(1 - 0.3429271969)(0.2429271969) = 0.0547383321`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.7751167223 = 0.7376285383 + 1.000000(0.0547383321)(0.6848616407)`

:math:`w_2 = 0.7751167223 = 0.7376285383 + 1.000000(0.0547383321)(0.6848616407)`

:math:`bias = -0.3053319970 = -0.3600703291 + (1.0000000000)(0.0547383321)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0087143176 = (0.6848616407)(0.3151383593)(0.054738)(0.737629)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4285865459 = 0.4198722284 + 1.000000(0.0087143176)(1.0000000000)`

:math:`w_2 = 0.4285865459 = 0.4198722284 + 1.000000(0.0087143176)(1.0000000000)`

:math:`bias = -0.0548250838 = -0.0635394014 + (1.0000000000)(0.0087143176)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0087143176 = (0.6848616407)(0.3151383593)(0.054738)(0.737629)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4285865459 = 0.4198722284 + 1.000000(0.0087143176)(1.0000000000)`

:math:`w_2 = 0.4285865459 = 0.4198722284 + 1.000000(0.0087143176)(1.0000000000)`

:math:`bias = -0.0548250838 = -0.0635394014 + (1.0000000000)(0.0087143176)`

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.5346820029              -0.4846820029             0.1174583220                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.5346820029)(1 - 0.4653179971)(-0.4846820029) = -0.1205875052`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.7405574138 = 0.7751167223 + 1.000000(-0.1205875052)(0.2865911228)`

:math:`w_2 = 0.7405574138 = 0.7751167223 + 1.000000(-0.1205875052)(0.2865911228)`

:math:`bias = -0.4259195021 = -0.3053319970 + (1.0000000000)(-0.1205875052)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0191104388 = (0.2865911228)(0.7134088772)(-0.120588)(0.775117)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4476969848 = 0.4285865459 + 1.000000(-0.0191104388)(-1.0000000000)`

:math:`w_2 = 0.4476969848 = 0.4285865459 + 1.000000(-0.0191104388)(-1.0000000000)`

:math:`bias = -0.0739355226 = -0.0548250838 + (1.0000000000)(-0.0191104388)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0191104388 = (0.2865911228)(0.7134088772)(-0.120588)(0.775117)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4476969848 = 0.4285865459 + 1.000000(-0.0191104388)(-1.0000000000)`

:math:`w_2 = 0.4476969848 = 0.4285865459 + 1.000000(-0.0191104388)(-1.0000000000)`

:math:`bias = -0.0739355226 = -0.0548250838 + (1.0000000000)(-0.0191104388)`

Iteration 6
~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.6462926721              0.2537073279              0.0321837041                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.6462926721)(1 - 0.3537073279)(0.2537073279) = 0.0579971029`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.7808390604 = 0.7405574138 + 1.000000(0.0579971029)(0.6945458402)`

:math:`w_2 = 0.7808390604 = 0.7405574138 + 1.000000(0.0579971029)(0.6945458402)`

:math:`bias = -0.3679223992 = -0.4259195021 + (1.0000000000)(0.0579971029)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0091119640 = (0.6945458402)(0.3054541598)(0.057997)(0.740557)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4568089487 = 0.4476969848 + 1.000000(0.0091119640)(1.0000000000)`

:math:`w_2 = 0.4568089487 = 0.4476969848 + 1.000000(0.0091119640)(1.0000000000)`

:math:`bias = -0.0648235587 = -0.0739355226 + (1.0000000000)(0.0091119640)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0091119640 = (0.6945458402)(0.3054541598)(0.057997)(0.740557)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4568089487 = 0.4476969848 + 1.000000(0.0091119640)(1.0000000000)`

:math:`w_2 = 0.4568089487 = 0.4476969848 + 1.000000(0.0091119640)(1.0000000000)`

:math:`bias = -0.0648235587 = -0.0739355226 + (1.0000000000)(0.0091119640)`

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.5146782430              -0.4646782430             0.1079629348                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.5146782430)(1 - 0.4853217570)(-0.4646782430) = -0.1160694455`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.7491287553 = 0.7808390604 + 1.000000(-0.1160694455)(0.2732011423)`

:math:`w_2 = 0.7491287553 = 0.7808390604 + 1.000000(-0.1160694455)(0.2732011423)`

:math:`bias = -0.4839918446 = -0.3679223992 + (1.0000000000)(-0.1160694455)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0179960084 = (0.2732011423)(0.7267988577)(-0.116069)(0.780839)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4748049571 = 0.4568089487 + 1.000000(-0.0179960084)(-1.0000000000)`

:math:`w_2 = 0.4748049571 = 0.4568089487 + 1.000000(-0.0179960084)(-1.0000000000)`

:math:`bias = -0.0828195671 = -0.0648235587 + (1.0000000000)(-0.0179960084)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0179960084 = (0.2732011423)(0.7267988577)(-0.116069)(0.780839)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4748049571 = 0.4568089487 + 1.000000(-0.0179960084)(-1.0000000000)`

:math:`w_2 = 0.4748049571 = 0.4568089487 + 1.000000(-0.0179960084)(-1.0000000000)`

:math:`bias = -0.0828195671 = -0.0648235587 + (1.0000000000)(-0.0179960084)`

Iteration 7
~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.6389702206              0.2610297794              0.0340682729                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.6389702206)(1 - 0.3610297794)(0.2610297794) = 0.0602162492`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.7915256553 = 0.7491287553 + 1.000000(0.0602162492)(0.7040773974)`

:math:`w_2 = 0.7915256553 = 0.7491287553 + 1.000000(0.0602162492)(0.7040773974)`

:math:`bias = -0.4237755954 = -0.4839918446 + (1.0000000000)(0.0602162492)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0093987199 = (0.7040773974)(0.2959226026)(0.060216)(0.749129)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4842036770 = 0.4748049571 + 1.000000(0.0093987199)(1.0000000000)`

:math:`w_2 = 0.4842036770 = 0.4748049571 + 1.000000(0.0093987199)(1.0000000000)`

:math:`bias = -0.0734208471 = -0.0828195671 + (1.0000000000)(0.0093987199)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0093987199 = (0.7040773974)(0.2959226026)(0.060216)(0.749129)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4842036770 = 0.4748049571 + 1.000000(0.0093987199)(1.0000000000)`

:math:`w_2 = 0.4842036770 = 0.4748049571 + 1.000000(0.0093987199)(1.0000000000)`

:math:`bias = -0.0734208471 = -0.0828195671 + (1.0000000000)(0.0093987199)`

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.4972700429              -0.4472700429             0.1000252456                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.4972700429)(1 - 0.5027299571)(-0.4472700429) = -0.1118141774`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.7623648091 = 0.7915256553 + 1.000000(-0.1118141774)(0.2607973953)`

:math:`w_2 = 0.7623648091 = 0.7915256553 + 1.000000(-0.1118141774)(0.2607973953)`

:math:`bias = -0.5355897728 = -0.4237755954 + (1.0000000000)(-0.1118141774)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0170619477 = (0.2607973953)(0.7392026047)(-0.111814)(0.791526)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5012656248 = 0.4842036770 + 1.000000(-0.0170619477)(-1.0000000000)`

:math:`w_2 = 0.5012656248 = 0.4842036770 + 1.000000(-0.0170619477)(-1.0000000000)`

:math:`bias = -0.0904827948 = -0.0734208471 + (1.0000000000)(-0.0170619477)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0170619477 = (0.2607973953)(0.7392026047)(-0.111814)(0.791526)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5012656248 = 0.4842036770 + 1.000000(-0.0170619477)(-1.0000000000)`

:math:`w_2 = 0.5012656248 = 0.4842036770 + 1.000000(-0.0170619477)(-1.0000000000)`

:math:`bias = -0.0904827948 = -0.0734208471 + (1.0000000000)(-0.0170619477)`

Iteration 8
~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.6346415781              0.2653584219              0.0352075460                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.6346415781)(1 - 0.3653584219)(0.2653584219) = 0.0615290939`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.8062608434 = 0.7623648091 + 1.000000(0.0615290939)(0.7134191570)`

:math:`w_2 = 0.8062608434 = 0.7623648091 + 1.000000(0.0615290939)(0.7134191570)`

:math:`bias = -0.4740606789 = -0.5355897728 + (1.0000000000)(0.0615290939)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0095903683 = (0.7134191570)(0.2865808430)(0.061529)(0.762365)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5108559930 = 0.5012656248 + 1.000000(0.0095903683)(1.0000000000)`

:math:`w_2 = 0.5108559930 = 0.5012656248 + 1.000000(0.0095903683)(1.0000000000)`

:math:`bias = -0.0808924266 = -0.0904827948 + (1.0000000000)(0.0095903683)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0095903683 = (0.7134191570)(0.2865808430)(0.061529)(0.762365)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5108559930 = 0.5012656248 + 1.000000(0.0095903683)(1.0000000000)`

:math:`w_2 = 0.5108559930 = 0.5012656248 + 1.000000(0.0095903683)(1.0000000000)`

:math:`bias = -0.0808924266 = -0.0904827948 + (1.0000000000)(0.0095903683)`

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.4819738006              -0.4319738006             0.0933006822                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.4819738006)(1 - 0.5180261994)(-0.4319738006) = -0.1078530829`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.7793782226 = 0.8062608434 + 1.000000(-0.1078530829)(0.2492522241)`

:math:`w_2 = 0.7793782226 = 0.8062608434 + 1.000000(-0.1078530829)(0.2492522241)`

:math:`bias = -0.5819137618 = -0.4740606789 + (1.0000000000)(-0.1078530829)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0162720110 = (0.2492522241)(0.7507477759)(-0.107853)(0.806261)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5271280040 = 0.5108559930 + 1.000000(-0.0162720110)(-1.0000000000)`

:math:`w_2 = 0.5271280040 = 0.5108559930 + 1.000000(-0.0162720110)(-1.0000000000)`

:math:`bias = -0.0971644376 = -0.0808924266 + (1.0000000000)(-0.0162720110)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0162720110 = (0.2492522241)(0.7507477759)(-0.107853)(0.806261)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5271280040 = 0.5108559930 + 1.000000(-0.0162720110)(-1.0000000000)`

:math:`w_2 = 0.5271280040 = 0.5108559930 + 1.000000(-0.0162720110)(-1.0000000000)`

:math:`bias = -0.0971644376 = -0.0808924266 + (1.0000000000)(-0.0162720110)`

Iteration 9
~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.6328234632              0.2671765368              0.0356916509                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.6328234632)(1 - 0.3671765368)(0.2671765368) = 0.0620805864`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.8242338743 = 0.7793782226 + 1.000000(0.0620805864)(0.7225391113)`

:math:`w_2 = 0.8242338743 = 0.7793782226 + 1.000000(0.0620805864)(0.7225391113)`

:math:`bias = -0.5198331754 = -0.5819137618 + (1.0000000000)(0.0620805864)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0096998990 = (0.7225391113)(0.2774608887)(0.062081)(0.779378)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5368279030 = 0.5271280040 + 1.000000(0.0096998990)(1.0000000000)`

:math:`w_2 = 0.5368279030 = 0.5271280040 + 1.000000(0.0096998990)(1.0000000000)`

:math:`bias = -0.0874645386 = -0.0971644376 + (1.0000000000)(0.0096998990)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0096998990 = (0.7225391113)(0.2774608887)(0.062081)(0.779378)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5368279030 = 0.5271280040 + 1.000000(0.0096998990)(1.0000000000)`

:math:`w_2 = 0.5368279030 = 0.5271280040 + 1.000000(0.0096998990)(1.0000000000)`

:math:`bias = -0.0874645386 = -0.0971644376 + (1.0000000000)(0.0096998990)`

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.4683590040              -0.4183590040             0.0875121281                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.4683590040)(1 - 0.5316409960)(-0.4183590040) = -0.1041709098`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.7993928862 = 0.8242338743 + 1.000000(-0.1041709098)(0.2384637723)`

:math:`w_2 = 0.7993928862 = 0.8242338743 + 1.000000(-0.1041709098)(0.2384637723)`

:math:`bias = -0.6240040852 = -0.5198331754 + (1.0000000000)(-0.1041709098)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0155922897 = (0.2384637723)(0.7615362277)(-0.104171)(0.824234)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5524201926 = 0.5368279030 + 1.000000(-0.0155922897)(-1.0000000000)`

:math:`w_2 = 0.5524201926 = 0.5368279030 + 1.000000(-0.0155922897)(-1.0000000000)`

:math:`bias = -0.1030568283 = -0.0874645386 + (1.0000000000)(-0.0155922897)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0155922897 = (0.2384637723)(0.7615362277)(-0.104171)(0.824234)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5524201926 = 0.5368279030 + 1.000000(-0.0155922897)(-1.0000000000)`

:math:`w_2 = 0.5524201926 = 0.5368279030 + 1.000000(-0.0155922897)(-1.0000000000)`

:math:`bias = -0.1030568283 = -0.0874645386 + (1.0000000000)(-0.0155922897)`

Iteration 10
~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.6330589604              0.2669410396              0.0356287593                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.6330589604)(1 - 0.3669410396)(0.2669410396) = 0.0620091524`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.8447469447 = 0.7993928862 + 1.000000(0.0620091524)(0.7314091027)`

:math:`w_2 = 0.8447469447 = 0.7993928862 + 1.000000(0.0620091524)(0.7314091027)`

:math:`bias = -0.5619949328 = -0.6240040852 + (1.0000000000)(0.0620091524)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0097379541 = (0.7314091027)(0.2685908973)(0.062009)(0.799393)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5621581468 = 0.5524201926 + 1.000000(0.0097379541)(1.0000000000)`

:math:`w_2 = 0.5621581468 = 0.5524201926 + 1.000000(0.0097379541)(1.0000000000)`

:math:`bias = -0.0933188741 = -0.1030568283 + (1.0000000000)(0.0097379541)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0097379541 = (0.7314091027)(0.2685908973)(0.062009)(0.799393)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5621581468 = 0.5524201926 + 1.000000(0.0097379541)(1.0000000000)`

:math:`w_2 = 0.5621581468 = 0.5524201926 + 1.000000(0.0097379541)(1.0000000000)`

:math:`bias = -0.0933188741 = -0.1030568283 + (1.0000000000)(0.0097379541)`

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.4560650700              -0.4060650700             0.0824444205                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.4560650700)(1 - 0.5439349300)(-0.4060650700) = -0.1007324490`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.8217443994 = 0.8447469447 + 1.000000(-0.1007324490)(0.2283528849)`

:math:`w_2 = 0.8217443994 = 0.8447469447 + 1.000000(-0.1007324490)(0.2283528849)`

:math:`bias = -0.6627273818 = -0.5619949328 + (1.0000000000)(-0.1007324490)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0149941296 = (0.2283528849)(0.7716471151)(-0.100732)(0.844747)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5771522764 = 0.5621581468 + 1.000000(-0.0149941296)(-1.0000000000)`

:math:`w_2 = 0.5771522764 = 0.5621581468 + 1.000000(-0.0149941296)(-1.0000000000)`

:math:`bias = -0.1083130038 = -0.0933188741 + (1.0000000000)(-0.0149941296)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0149941296 = (0.2283528849)(0.7716471151)(-0.100732)(0.844747)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5771522764 = 0.5621581468 + 1.000000(-0.0149941296)(-1.0000000000)`

:math:`w_2 = 0.5771522764 = 0.5621581468 + 1.000000(-0.0149941296)(-1.0000000000)`

:math:`bias = -0.1083130038 = -0.0933188741 + (1.0000000000)(-0.0149941296)`

Iteration 11
~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.6349383352              0.2650616648              0.0351288431                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.6349383352)(1 - 0.3650616648)(0.2650616648) = 0.0614390795`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.8672095900 = 0.8217443994 + 1.000000(0.0614390795)(0.7400044240)`

:math:`w_2 = 0.8672095900 = 0.8217443994 + 1.000000(0.0614390795)(0.7400044240)`

:math:`bias = -0.6012883023 = -0.6627273818 + (1.0000000000)(0.0614390795)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0097136338 = (0.7400044240)(0.2599955760)(0.061439)(0.821744)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5868659102 = 0.5771522764 + 1.000000(0.0097136338)(1.0000000000)`

:math:`w_2 = 0.5868659102 = 0.5771522764 + 1.000000(0.0097136338)(1.0000000000)`

:math:`bias = -0.0985993700 = -0.1083130038 + (1.0000000000)(0.0097136338)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0097136338 = (0.7400044240)(0.2599955760)(0.061439)(0.821744)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5868659102 = 0.5771522764 + 1.000000(0.0097136338)(1.0000000000)`

:math:`w_2 = 0.5868659102 = 0.5771522764 + 1.000000(0.0097136338)(1.0000000000)`

:math:`bias = -0.0985993700 = -0.1083130038 + (1.0000000000)(0.0097136338)`

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.4448018918              -0.3948018918             0.0779342669                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.4448018918)(1 - 0.5551981082)(-0.3948018918) = -0.0974975783`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.8458714210 = 0.8672095900 + 1.000000(-0.0974975783)(0.2188584519)`

:math:`w_2 = 0.8458714210 = 0.8672095900 + 1.000000(-0.0974975783)(0.2188584519)`

:math:`bias = -0.6987858805 = -0.6012883023 + (1.0000000000)(-0.0974975783)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0144547625 = (0.2188584519)(0.7811415481)(-0.097498)(0.867210)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.6013206728 = 0.5868659102 + 1.000000(-0.0144547625)(-1.0000000000)`

:math:`w_2 = 0.6013206728 = 0.5868659102 + 1.000000(-0.0144547625)(-1.0000000000)`

:math:`bias = -0.1130541325 = -0.0985993700 + (1.0000000000)(-0.0144547625)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0144547625 = (0.2188584519)(0.7811415481)(-0.097498)(0.867210)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.6013206728 = 0.5868659102 + 1.000000(-0.0144547625)(-1.0000000000)`

:math:`w_2 = 0.6013206728 = 0.5868659102 + 1.000000(-0.0144547625)(-1.0000000000)`

:math:`bias = -0.1130541325 = -0.0985993700 + (1.0000000000)(-0.0144547625)`

Iteration 12
~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.6381057608              0.2618942392              0.0342942963                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.6381057608)(1 - 0.3618942392)(0.2618942392) = 0.0604783983`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.8911276473 = 0.8458714210 + 1.000000(0.0604783983)(0.7483039832)`

:math:`w_2 = 0.8911276473 = 0.8458714210 + 1.000000(0.0604783983)(0.7483039832)`

:math:`bias = -0.6383074822 = -0.6987858805 + (1.0000000000)(0.0604783983)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0096351623 = (0.7483039832)(0.2516960168)(0.060478)(0.845871)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.6109558350 = 0.6013206728 + 1.000000(0.0096351623)(1.0000000000)`

:math:`w_2 = 0.6109558350 = 0.6013206728 + 1.000000(0.0096351623)(1.0000000000)`

:math:`bias = -0.1034189703 = -0.1130541325 + (1.0000000000)(0.0096351623)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0096351623 = (0.7483039832)(0.2516960168)(0.060478)(0.845871)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.6109558350 = 0.6013206728 + 1.000000(0.0096351623)(1.0000000000)`

:math:`w_2 = 0.6109558350 = 0.6013206728 + 1.000000(0.0096351623)(1.0000000000)`

:math:`bias = -0.1034189703 = -0.1130541325 + (1.0000000000)(0.0096351623)`

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.4343429192              -0.3843429192             0.0738597398                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.4343429192)(1 - 0.5656570808)(-0.3843429192) = -0.0944288843`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.8713039291 = 0.8911276473 + 1.000000(-0.0944288843)(0.2099327810)`

:math:`w_2 = 0.8713039291 = 0.8911276473 + 1.000000(-0.0944288843)(0.2099327810)`

:math:`bias = -0.7327363665 = -0.6383074822 + (1.0000000000)(-0.0944288843)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0139569036 = (0.2099327810)(0.7900672190)(-0.094429)(0.891128)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.6249127386 = 0.6109558350 + 1.000000(-0.0139569036)(-1.0000000000)`

:math:`w_2 = 0.6249127386 = 0.6109558350 + 1.000000(-0.0139569036)(-1.0000000000)`

:math:`bias = -0.1173758738 = -0.1034189703 + (1.0000000000)(-0.0139569036)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0139569036 = (0.2099327810)(0.7900672190)(-0.094429)(0.891128)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.6249127386 = 0.6109558350 + 1.000000(-0.0139569036)(-1.0000000000)`

:math:`w_2 = 0.6249127386 = 0.6109558350 + 1.000000(-0.0139569036)(-1.0000000000)`

:math:`bias = -0.1173758738 = -0.1034189703 + (1.0000000000)(-0.0139569036)`

Iteration 13
~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.6422588460              0.2577411540              0.0332152512                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.6422588460)(1 - 0.3577411540)(0.2577411540) = 0.0592192315`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.9160908820 = 0.8713039291 + 1.000000(0.0592192315)(0.7562906814)`

:math:`w_2 = 0.9160908820 = 0.8713039291 + 1.000000(0.0592192315)(0.7562906814)`

:math:`bias = -0.6735171350 = -0.7327363665 + (1.0000000000)(0.0592192315)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0095102805 = (0.7562906814)(0.2437093186)(0.059219)(0.871304)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.6344230190 = 0.6249127386 + 1.000000(0.0095102805)(1.0000000000)`

:math:`w_2 = 0.6344230190 = 0.6249127386 + 1.000000(0.0095102805)(1.0000000000)`

:math:`bias = -0.1078655934 = -0.1173758738 + (1.0000000000)(0.0095102805)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0095102805 = (0.7562906814)(0.2437093186)(0.059219)(0.871304)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.6344230190 = 0.6249127386 + 1.000000(0.0095102805)(1.0000000000)`

:math:`w_2 = 0.6344230190 = 0.6249127386 + 1.000000(0.0095102805)(1.0000000000)`

:math:`bias = -0.1078655934 = -0.1173758738 + (1.0000000000)(0.0095102805)`

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.4245155586              -0.3745155586             0.0701309518                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.4245155586)(1 - 0.5754844414)(-0.3745155586) = -0.0914949371`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.8976512078 = 0.9160908820 + 1.000000(-0.0914949371)(0.2015376454)`

:math:`w_2 = 0.8976512078 = 0.9160908820 + 1.000000(-0.0914949371)(0.2015376454)`

:math:`bias = -0.7650120721 = -0.6735171350 + (1.0000000000)(-0.0914949371)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0134879594 = (0.2015376454)(0.7984623546)(-0.091495)(0.916091)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.6479109784 = 0.6344230190 + 1.000000(-0.0134879594)(-1.0000000000)`

:math:`w_2 = 0.6479109784 = 0.6344230190 + 1.000000(-0.0134879594)(-1.0000000000)`

:math:`bias = -0.1213535527 = -0.1078655934 + (1.0000000000)(-0.0134879594)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0134879594 = (0.2015376454)(0.7984623546)(-0.091495)(0.916091)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.6479109784 = 0.6344230190 + 1.000000(-0.0134879594)(-1.0000000000)`

:math:`w_2 = 0.6479109784 = 0.6344230190 + 1.000000(-0.0134879594)(-1.0000000000)`

:math:`bias = -0.1213535527 = -0.1078655934 + (1.0000000000)(-0.0134879594)`

Iteration 14
~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.6471448124              0.2528551876              0.0319678729                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.6471448124)(1 - 0.3528551876)(0.2528551876) = 0.0577390786`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.9417610780 = 0.8976512078 + 1.000000(0.0577390786)(0.7639517508)`

:math:`w_2 = 0.9417610780 = 0.8976512078 + 1.000000(0.0577390786)(0.7639517508)`

:math:`bias = -0.7072729936 = -0.7650120721 + (1.0000000000)(0.0577390786)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0093463961 = (0.7639517508)(0.2360482492)(0.057739)(0.897651)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.6572573745 = 0.6479109784 + 1.000000(0.0093463961)(1.0000000000)`

:math:`w_2 = 0.6572573745 = 0.6479109784 + 1.000000(0.0093463961)(1.0000000000)`

:math:`bias = -0.1120071566 = -0.1213535527 + (1.0000000000)(0.0093463961)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0093463961 = (0.7639517508)(0.2360482492)(0.057739)(0.897651)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.6572573745 = 0.6479109784 + 1.000000(0.0093463961)(1.0000000000)`

:math:`w_2 = 0.6572573745 = 0.6479109784 + 1.000000(0.0093463961)(1.0000000000)`

:math:`bias = -0.1120071566 = -0.1213535527 + (1.0000000000)(0.0093463961)`

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.4151912723              -0.3651912723             0.0666823327                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.4151912723)(1 - 0.5848087277)(-0.3651912723) = -0.0886711724`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.9245906866 = 0.9417610780 + 1.000000(-0.0886711724)(0.1936411902)`

:math:`w_2 = 0.9245906866 = 0.9417610780 + 1.000000(-0.0886711724)(0.1936411902)`

:math:`bias = -0.7959441660 = -0.7072729936 + (1.0000000000)(-0.0886711724)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0130391496 = (0.1936411902)(0.8063588098)(-0.088671)(0.941761)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.6702965241 = 0.6572573745 + 1.000000(-0.0130391496)(-1.0000000000)`

:math:`w_2 = 0.6702965241 = 0.6572573745 + 1.000000(-0.0130391496)(-1.0000000000)`

:math:`bias = -0.1250463062 = -0.1120071566 + (1.0000000000)(-0.0130391496)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0130391496 = (0.1936411902)(0.8063588098)(-0.088671)(0.941761)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.6702965241 = 0.6572573745 + 1.000000(-0.0130391496)(-1.0000000000)`

:math:`w_2 = 0.6702965241 = 0.6572573745 + 1.000000(-0.0130391496)(-1.0000000000)`

:math:`bias = -0.1250463062 = -0.1120071566 + (1.0000000000)(-0.0130391496)`

Iteration 15
~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.6525553127              0.2474446873              0.0306144366                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.6525553127)(1 - 0.3474446873)(0.2474446873) = 0.0561023611`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.9678612545 = 0.9245906866 + 1.000000(0.0561023611)(0.7712789094)`

:math:`w_2 = 0.9678612545 = 0.9245906866 + 1.000000(0.0561023611)(0.7712789094)`

:math:`bias = -0.7398418049 = -0.7959441660 + (1.0000000000)(0.0561023611)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0091505737 = (0.7712789094)(0.2287210906)(0.056102)(0.924591)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.6794470978 = 0.6702965241 + 1.000000(0.0091505737)(1.0000000000)`

:math:`w_2 = 0.6794470978 = 0.6702965241 + 1.000000(0.0091505737)(1.0000000000)`

:math:`bias = -0.1158957325 = -0.1250463062 + (1.0000000000)(0.0091505737)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0091505737 = (0.7712789094)(0.2287210906)(0.056102)(0.924591)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.6794470978 = 0.6702965241 + 1.000000(0.0091505737)(1.0000000000)`

:math:`w_2 = 0.6794470978 = 0.6702965241 + 1.000000(0.0091505737)(1.0000000000)`

:math:`bias = -0.1158957325 = -0.1250463062 + (1.0000000000)(0.0091505737)`

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.4062764518              -0.3562764518             0.0634664551                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.4062764518)(1 - 0.5937235482)(-0.3562764518) = -0.0859395437`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.9518579656 = 0.9678612545 + 1.000000(-0.0859395437)(0.1862156600)`

:math:`w_2 = 0.9518579656 = 0.9678612545 + 1.000000(-0.0859395437)(0.1862156600)`

:math:`bias = -0.8257813486 = -0.7398418049 + (1.0000000000)(-0.0859395437)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0126046757 = (0.1862156600)(0.8137843400)(-0.085940)(0.967861)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.6920517735 = 0.6794470978 + 1.000000(-0.0126046757)(-1.0000000000)`

:math:`w_2 = 0.6920517735 = 0.6794470978 + 1.000000(-0.0126046757)(-1.0000000000)`

:math:`bias = -0.1285004082 = -0.1158957325 + (1.0000000000)(-0.0126046757)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0126046757 = (0.1862156600)(0.8137843400)(-0.085940)(0.967861)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.6920517735 = 0.6794470978 + 1.000000(-0.0126046757)(-1.0000000000)`

:math:`w_2 = 0.6920517735 = 0.6794470978 + 1.000000(-0.0126046757)(-1.0000000000)`

:math:`bias = -0.1285004082 = -0.1158957325 + (1.0000000000)(-0.0126046757)`


.. _alternating-training-final:

Method 1 - Final Network
~~~~~~~~~~~~~~~~~~~~~~~~

.. graphviz::

    digraph network{
    rankdir=LR;
    node [shape=plaintext,width=0.25,label=<x<SUB>1</SUB>>]; x_1;
    node [shape=plaintext,width=0.25,label=<x<SUB>2</SUB>>]; x_2;
    node [shape=square,width=.25,fillcolor=black,style=filled,label=""]; input_0, input_1
    node [shape=circle,width=.5,fillcolor=white,label="-0.128500"]; h_0_0;
    node [shape=circle,width=.5,fillcolor=white,label="-0.128500"]; h_0_1;
    node [shape=circle,width=.5,fillcolor=white,label="-0.825781"]; o_0;
    node [shape=circle,width=.5,style=invisible,label=""]; output;
    
    
    x_1 -> input_0;
    x_2 -> input_1;
    input_0 -> h_0_0 [label="0.692052"];
    input_1 -> h_0_0 [label="0.692052"];
    input_0 -> h_0_1 [label="0.692052"];
    input_1 -> h_0_1 [label="0.692052"];
    h_0_0 -> o_0 [label="0.951858"];
    h_0_1 -> o_0 [label="0.951858"];
    o_0 -> output [label="Output"];
    }
    


.. _alternating-validation-test:

Alternating Training Final Feed Forward Epoch Test
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

These are the results after 15 iterations of training as described above.

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.6583208714              0.2416791286              0.0292044006                       
=========================== ========================= ========================= ==================================

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.3817659623              -0.3317659623             0.0550343269                       
=========================== ========================= ========================= ==================================


Successive Training Method
--------------------------


For each input/output pair in the training set, present the pair and perform the back propagation
technique to update the weights for the specified number of iterations. Then move onto the next
input/output pair and repeat until no more training data is available.

These are the results of executing 15 iterations of training with this method with the following
inputs:

.. math:: ( 1, 1) \rightarrow 0.9

.. math:: (-1, -1) \rightarrow 0.05


.. contents:: Iterations
    :depth: 1
    :local:


Input 1 - Iteration 1
~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.7375067919              0.1624932081              0.0132020213                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.7375067919)(1 - 0.2624932081)(0.1624932081) = 0.0314571453`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.8203105042 = 0.8000000000 + 1.000000(0.0314571453)(0.6456563062)`

:math:`w_2 = 0.8203105042 = 0.8000000000 + 1.000000(0.0314571453)(0.6456563062)`

:math:`bias = 0.0314571453 = 0.0000000000 + (1.0000000000)(0.0314571453)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0057575193 = (0.6456563062)(0.3543436938)(0.031457)(0.800000)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3057575193 = 0.3000000000 + 1.000000(0.0057575193)(1.0000000000)`

:math:`w_2 = 0.3057575193 = 0.3000000000 + 1.000000(0.0057575193)(1.0000000000)`

:math:`bias = 0.0057575193 = 0.0000000000 + (1.0000000000)(0.0057575193)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0057575193 = (0.6456563062)(0.3543436938)(0.031457)(0.800000)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3057575193 = 0.3000000000 + 1.000000(0.0057575193)(1.0000000000)`

:math:`w_2 = 0.3057575193 = 0.3000000000 + 1.000000(0.0057575193)(1.0000000000)`

:math:`bias = 0.0057575193 = 0.0000000000 + (1.0000000000)(0.0057575193)`

Input 1 - Iteration 2
~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.7497353349              0.1502646651              0.0112897348                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.7497353349)(1 - 0.2502646651)(0.1502646651) = 0.0281944991`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.8386255939 = 0.8203105042 + 1.000000(0.0281944991)(0.6495979806)`

:math:`w_2 = 0.8386255939 = 0.8203105042 + 1.000000(0.0281944991)(0.6495979806)`

:math:`bias = 0.0596516443 = 0.0314571453 + (1.0000000000)(0.0281944991)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0052644611 = (0.6495979806)(0.3504020194)(0.028194)(0.820311)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3110219804 = 0.3057575193 + 1.000000(0.0052644611)(1.0000000000)`

:math:`w_2 = 0.3110219804 = 0.3057575193 + 1.000000(0.0052644611)(1.0000000000)`

:math:`bias = 0.0110219804 = 0.0057575193 + (1.0000000000)(0.0052644611)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0052644611 = (0.6495979806)(0.3504020194)(0.028194)(0.820311)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3110219804 = 0.3057575193 + 1.000000(0.0052644611)(1.0000000000)`

:math:`w_2 = 0.3110219804 = 0.3057575193 + 1.000000(0.0052644611)(1.0000000000)`

:math:`bias = 0.0110219804 = 0.0057575193 + (1.0000000000)(0.0052644611)`

Input 1 - Iteration 3
~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.7604604993              0.1395395007              0.0097356361                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.7604604993)(1 - 0.2395395007)(0.1395395007) = 0.0254185612`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.8552285998 = 0.8386255939 + 1.000000(0.0254185612)(0.6531843296)`

:math:`w_2 = 0.8552285998 = 0.8386255939 + 1.000000(0.0254185612)(0.6531843296)`

:math:`bias = 0.0850702056 = 0.0596516443 + (1.0000000000)(0.0254185612)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0048289593 = (0.6531843296)(0.3468156704)(0.025419)(0.838626)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3158509397 = 0.3110219804 + 1.000000(0.0048289593)(1.0000000000)`

:math:`w_2 = 0.3158509397 = 0.3110219804 + 1.000000(0.0048289593)(1.0000000000)`

:math:`bias = 0.0158509397 = 0.0110219804 + (1.0000000000)(0.0048289593)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0048289593 = (0.6531843296)(0.3468156704)(0.025419)(0.838626)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3158509397 = 0.3110219804 + 1.000000(0.0048289593)(1.0000000000)`

:math:`w_2 = 0.3158509397 = 0.3110219804 + 1.000000(0.0048289593)(1.0000000000)`

:math:`bias = 0.0158509397 = 0.0110219804 + (1.0000000000)(0.0048289593)`

Input 1 - Iteration 4
~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.7699297995              0.1300702005              0.0084591285                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.7699297995)(1 - 0.2300702005)(0.1300702005) = 0.0230403626`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.8703536482 = 0.8552285998 + 1.000000(0.0230403626)(0.6564587844)`

:math:`w_2 = 0.8703536482 = 0.8552285998 + 1.000000(0.0230403626)(0.6564587844)`

:math:`bias = 0.1081105682 = 0.0850702056 + (1.0000000000)(0.0230403626)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0044438341 = (0.6564587844)(0.3435412156)(0.023040)(0.855229)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3202947738 = 0.3158509397 + 1.000000(0.0044438341)(1.0000000000)`

:math:`w_2 = 0.3202947738 = 0.3158509397 + 1.000000(0.0044438341)(1.0000000000)`

:math:`bias = 0.0202947738 = 0.0158509397 + (1.0000000000)(0.0044438341)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0044438341 = (0.6564587844)(0.3435412156)(0.023040)(0.855229)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3202947738 = 0.3158509397 + 1.000000(0.0044438341)(1.0000000000)`

:math:`w_2 = 0.3202947738 = 0.3158509397 + 1.000000(0.0044438341)(1.0000000000)`

:math:`bias = 0.0202947738 = 0.0158509397 + (1.0000000000)(0.0044438341)`

Input 1 - Iteration 5
~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.7783429174              0.1216570826              0.0074002229                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.7783429174)(1 - 0.2216570826)(0.1216570826) = 0.0209889150`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.8841949773 = 0.8703536482 + 1.000000(0.0209889150)(0.6594590110)`

:math:`w_2 = 0.8841949773 = 0.8703536482 + 1.000000(0.0209889150)(0.6594590110)`

:math:`bias = 0.1290994832 = 0.1081105682 + (1.0000000000)(0.0209889150)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0041024467 = (0.6594590110)(0.3405409890)(0.020989)(0.870354)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3243972205 = 0.3202947738 + 1.000000(0.0041024467)(1.0000000000)`

:math:`w_2 = 0.3243972205 = 0.3202947738 + 1.000000(0.0041024467)(1.0000000000)`

:math:`bias = 0.0243972205 = 0.0202947738 + (1.0000000000)(0.0041024467)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0041024467 = (0.6594590110)(0.3405409890)(0.020989)(0.870354)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3243972205 = 0.3202947738 + 1.000000(0.0041024467)(1.0000000000)`

:math:`w_2 = 0.3243972205 = 0.3202947738 + 1.000000(0.0041024467)(1.0000000000)`

:math:`bias = 0.0243972205 = 0.0202947738 + (1.0000000000)(0.0041024467)`

Input 1 - Iteration 6
~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.7858616035              0.1141383965              0.0065137868                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.7858616035)(1 - 0.2141383965)(0.1141383965) = 0.0192075682`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.8969145642 = 0.8841949773 + 1.000000(0.0192075682)(0.6622174568)`

:math:`w_2 = 0.8969145642 = 0.8841949773 + 1.000000(0.0192075682)(0.6622174568)`

:math:`bias = 0.1483070513 = 0.1290994832 + (1.0000000000)(0.0192075682)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0037989034 = (0.6622174568)(0.3377825432)(0.019208)(0.884195)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3281961239 = 0.3243972205 + 1.000000(0.0037989034)(1.0000000000)`

:math:`w_2 = 0.3281961239 = 0.3243972205 + 1.000000(0.0037989034)(1.0000000000)`

:math:`bias = 0.0281961239 = 0.0243972205 + (1.0000000000)(0.0037989034)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0037989034 = (0.6622174568)(0.3377825432)(0.019208)(0.884195)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3281961239 = 0.3243972205 + 1.000000(0.0037989034)(1.0000000000)`

:math:`w_2 = 0.3281961239 = 0.3243972205 + 1.000000(0.0037989034)(1.0000000000)`

:math:`bias = 0.0281961239 = 0.0243972205 + (1.0000000000)(0.0037989034)`

Input 1 - Iteration 7
~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.7926176071              0.1073823929              0.0057654891                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.7926176071)(1 - 0.2073823929)(0.1073823929) = 0.0176509740`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.9086482611 = 0.8969145642 + 1.000000(0.0176509740)(0.6647620038)`

:math:`w_2 = 0.9086482611 = 0.8969145642 + 1.000000(0.0176509740)(0.6647620038)`

:math:`bias = 0.1659580253 = 0.1483070513 + (1.0000000000)(0.0176509740)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0035280861 = (0.6647620038)(0.3352379962)(0.017651)(0.896915)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3317242100 = 0.3281961239 + 1.000000(0.0035280861)(1.0000000000)`

:math:`w_2 = 0.3317242100 = 0.3281961239 + 1.000000(0.0035280861)(1.0000000000)`

:math:`bias = 0.0317242100 = 0.0281961239 + (1.0000000000)(0.0035280861)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0035280861 = (0.6647620038)(0.3352379962)(0.017651)(0.896915)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3317242100 = 0.3281961239 + 1.000000(0.0035280861)(1.0000000000)`

:math:`w_2 = 0.3317242100 = 0.3281961239 + 1.000000(0.0035280861)(1.0000000000)`

:math:`bias = 0.0317242100 = 0.0281961239 + (1.0000000000)(0.0035280861)`

Input 1 - Iteration 8
~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.7987189158              0.1012810842              0.0051289290                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.7987189158)(1 - 0.2012810842)(0.1012810842) = 0.0162826570`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.9195106921 = 0.9086482611 + 1.000000(0.0162826570)(0.6671166145)`

:math:`w_2 = 0.9195106921 = 0.9086482611 + 1.000000(0.0162826570)(0.6671166145)`

:math:`bias = 0.1822406823 = 0.1659580253 + (1.0000000000)(0.0162826570)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0032856020 = (0.6671166145)(0.3328833855)(0.016283)(0.908648)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3350098120 = 0.3317242100 + 1.000000(0.0032856020)(1.0000000000)`

:math:`w_2 = 0.3350098120 = 0.3317242100 + 1.000000(0.0032856020)(1.0000000000)`

:math:`bias = 0.0350098120 = 0.0317242100 + (1.0000000000)(0.0032856020)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0032856020 = (0.6671166145)(0.3328833855)(0.016283)(0.908648)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3350098120 = 0.3317242100 + 1.000000(0.0032856020)(1.0000000000)`

:math:`w_2 = 0.3350098120 = 0.3317242100 + 1.000000(0.0032856020)(1.0000000000)`

:math:`bias = 0.0350098120 = 0.0317242100 + (1.0000000000)(0.0032856020)`

Input 1 - Iteration 9
~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.8042546270              0.0957453730              0.0045835882                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.8042546270)(1 - 0.1957453730)(0.0957453730) = 0.0150731100`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.9295991535 = 0.9195106921 + 1.000000(0.0150731100)(0.6693019181)`

:math:`w_2 = 0.9295991535 = 0.9195106921 + 1.000000(0.0150731100)(0.6693019181)`

:math:`bias = 0.1973137923 = 0.1822406823 + (1.0000000000)(0.0150731100)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0030677036 = (0.6693019181)(0.3306980819)(0.015073)(0.919511)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3380775156 = 0.3350098120 + 1.000000(0.0030677036)(1.0000000000)`

:math:`w_2 = 0.3380775156 = 0.3350098120 + 1.000000(0.0030677036)(1.0000000000)`

:math:`bias = 0.0380775156 = 0.0350098120 + (1.0000000000)(0.0030677036)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0030677036 = (0.6693019181)(0.3306980819)(0.015073)(0.919511)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3380775156 = 0.3350098120 + 1.000000(0.0030677036)(1.0000000000)`

:math:`w_2 = 0.3380775156 = 0.3350098120 + 1.000000(0.0030677036)(1.0000000000)`

:math:`bias = 0.0380775156 = 0.0350098120 + (1.0000000000)(0.0030677036)`

Input 1 - Iteration 10
~~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.8092987448              0.0907012552              0.0041133588                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.8092987448)(1 - 0.1907012552)(0.0907012552) = 0.0139983135`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.9389967214 = 0.9295991535 + 1.000000(0.0139983135)(0.6713357225)`

:math:`w_2 = 0.9389967214 = 0.9295991535 + 1.000000(0.0139983135)(0.6713357225)`

:math:`bias = 0.2113121058 = 0.1973137923 + (1.0000000000)(0.0139983135)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0028712017 = (0.6713357225)(0.3286642775)(0.013998)(0.929599)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3409487172 = 0.3380775156 + 1.000000(0.0028712017)(1.0000000000)`

:math:`w_2 = 0.3409487172 = 0.3380775156 + 1.000000(0.0028712017)(1.0000000000)`

:math:`bias = 0.0409487172 = 0.0380775156 + (1.0000000000)(0.0028712017)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0028712017 = (0.6713357225)(0.3286642775)(0.013998)(0.929599)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3409487172 = 0.3380775156 + 1.000000(0.0028712017)(1.0000000000)`

:math:`w_2 = 0.3409487172 = 0.3380775156 + 1.000000(0.0028712017)(1.0000000000)`

:math:`bias = 0.0409487172 = 0.0380775156 + (1.0000000000)(0.0028712017)`

Input 1 - Iteration 11
~~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.8139131420              0.0860868580              0.0037054736                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.8139131420)(1 - 0.1860868580)(0.0860868580) = 0.0130385898`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.9477747362 = 0.9389967214 + 1.000000(0.0130385898)(0.6732334509)`

:math:`w_2 = 0.9477747362 = 0.9389967214 + 1.000000(0.0130385898)(0.6732334509)`

:math:`bias = 0.2243506956 = 0.2113121058 + (1.0000000000)(0.0130385898)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0026933821 = (0.6732334509)(0.3267665491)(0.013039)(0.938997)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3436420994 = 0.3409487172 + 1.000000(0.0026933821)(1.0000000000)`

:math:`w_2 = 0.3436420994 = 0.3409487172 + 1.000000(0.0026933821)(1.0000000000)`

:math:`bias = 0.0436420994 = 0.0409487172 + (1.0000000000)(0.0026933821)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0026933821 = (0.6732334509)(0.3267665491)(0.013039)(0.938997)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3436420994 = 0.3409487172 + 1.000000(0.0026933821)(1.0000000000)`

:math:`w_2 = 0.3436420994 = 0.3409487172 + 1.000000(0.0026933821)(1.0000000000)`

:math:`bias = 0.0436420994 = 0.0409487172 + (1.0000000000)(0.0026933821)`

Input 1 - Iteration 12
~~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.8181498805              0.0818501195              0.0033497210                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.8181498805)(1 - 0.1818501195)(0.0818501195) = 0.0121777143`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.9559947970 = 0.9477747362 + 1.000000(0.0121777143)(0.6750085094)`

:math:`w_2 = 0.9559947970 = 0.9477747362 + 1.000000(0.0121777143)(0.6750085094)`

:math:`bias = 0.2365284098 = 0.2243506956 + (1.0000000000)(0.0121777143)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0025319326 = (0.6750085094)(0.3249914906)(0.012178)(0.947775)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3461740320 = 0.3436420994 + 1.000000(0.0025319326)(1.0000000000)`

:math:`w_2 = 0.3461740320 = 0.3436420994 + 1.000000(0.0025319326)(1.0000000000)`

:math:`bias = 0.0461740320 = 0.0436420994 + (1.0000000000)(0.0025319326)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0025319326 = (0.6750085094)(0.3249914906)(0.012178)(0.947775)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3461740320 = 0.3436420994 + 1.000000(0.0025319326)(1.0000000000)`

:math:`w_2 = 0.3461740320 = 0.3436420994 + 1.000000(0.0025319326)(1.0000000000)`

:math:`bias = 0.0461740320 = 0.0436420994 + (1.0000000000)(0.0025319326)`

Input 1 - Iteration 13
~~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.8220530370              0.0779469630              0.0030378645                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.8220530370)(1 - 0.1779469630)(0.0779469630) = 0.0114022253`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.9637103703 = 0.9559947970 + 1.000000(0.0114022253)(0.6766725948)`

:math:`w_2 = 0.9637103703 = 0.9559947970 + 1.000000(0.0114022253)(0.6766725948)`

:math:`bias = 0.2479306351 = 0.2365284098 + (1.0000000000)(0.0114022253)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0023848785 = (0.6766725948)(0.3233274052)(0.011402)(0.955995)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3485589104 = 0.3461740320 + 1.000000(0.0023848785)(1.0000000000)`

:math:`w_2 = 0.3485589104 = 0.3461740320 + 1.000000(0.0023848785)(1.0000000000)`

:math:`bias = 0.0485589104 = 0.0461740320 + (1.0000000000)(0.0023848785)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0023848785 = (0.6766725948)(0.3233274052)(0.011402)(0.955995)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3485589104 = 0.3461740320 + 1.000000(0.0023848785)(1.0000000000)`

:math:`w_2 = 0.3485589104 = 0.3461740320 + 1.000000(0.0023848785)(1.0000000000)`

:math:`bias = 0.0485589104 = 0.0461740320 + (1.0000000000)(0.0023848785)`

Input 1 - Iteration 14
~~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.8256601475              0.0743398525              0.0027632068                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.8256601475)(1 - 0.1743398525)(0.0743398525) = 0.0107008849`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.9709680952 = 0.9637103703 + 1.000000(0.0107008849)(0.6782359518)`

:math:`w_2 = 0.9709680952 = 0.9637103703 + 1.000000(0.0107008849)(0.6782359518)`

:math:`bias = 0.2586315200 = 0.2479306351 + (1.0000000000)(0.0107008849)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0022505287 = (0.6782359518)(0.3217640482)(0.010701)(0.963710)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3508094391 = 0.3485589104 + 1.000000(0.0022505287)(1.0000000000)`

:math:`w_2 = 0.3508094391 = 0.3485589104 + 1.000000(0.0022505287)(1.0000000000)`

:math:`bias = 0.0508094391 = 0.0485589104 + (1.0000000000)(0.0022505287)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0022505287 = (0.6782359518)(0.3217640482)(0.010701)(0.963710)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3508094391 = 0.3485589104 + 1.000000(0.0022505287)(1.0000000000)`

:math:`w_2 = 0.3508094391 = 0.3485589104 + 1.000000(0.0022505287)(1.0000000000)`

:math:`bias = 0.0508094391 = 0.0485589104 + (1.0000000000)(0.0022505287)`

Input 1 - Iteration 15
~~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.8290033573              0.0709966427              0.0025202616                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.8290033573)(1 - 0.1709966427)(0.0709966427) = 0.0100642562`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.9778088465 = 0.9709680952 + 1.000000(0.0100642562)(0.6797075870)`

:math:`w_2 = 0.9778088465 = 0.9709680952 + 1.000000(0.0100642562)(0.6797075870)`

:math:`bias = 0.2686957762 = 0.2586315200 + (1.0000000000)(0.0100642562)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0021274307 = (0.6797075870)(0.3202924130)(0.010064)(0.970968)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3529368698 = 0.3508094391 + 1.000000(0.0021274307)(1.0000000000)`

:math:`w_2 = 0.3529368698 = 0.3508094391 + 1.000000(0.0021274307)(1.0000000000)`

:math:`bias = 0.0529368698 = 0.0508094391 + (1.0000000000)(0.0021274307)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = 0.0021274307 = (0.6797075870)(0.3202924130)(0.010064)(0.970968)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3529368698 = 0.3508094391 + 1.000000(0.0021274307)(1.0000000000)`

:math:`w_2 = 0.3529368698 = 0.3508094391 + 1.000000(0.0021274307)(1.0000000000)`

:math:`bias = 0.0529368698 = 0.0508094391 + (1.0000000000)(0.0021274307)`


.. _successive-training-input-1-15-rounds:

Result of 15 Iterations for Input 1
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.8321103416              0.0678896584              0.0023045029                       
=========================== ========================= ========================= ==================================

Input 2 - Iteration 1
~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.7187275371              -0.6687275371             0.2235982595                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.7187275371)(1 - 0.2812724629)(-0.6687275371) = -0.1351887983`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.9315299320 = 0.9778088465 + 1.000000(-0.1351887983)(0.3423280259)`

:math:`w_2 = 0.9315299320 = 0.9778088465 + 1.000000(-0.1351887983)(0.3423280259)`

:math:`bias = 0.1335069779 = 0.2686957762 + (1.0000000000)(-0.1351887983)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0297609274 = (0.3423280259)(0.6576719741)(-0.135189)(0.977809)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3826977972 = 0.3529368698 + 1.000000(-0.0297609274)(-1.0000000000)`

:math:`w_2 = 0.3826977972 = 0.3529368698 + 1.000000(-0.0297609274)(-1.0000000000)`

:math:`bias = 0.0231759423 = 0.0529368698 + (1.0000000000)(-0.0297609274)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0297609274 = (0.3423280259)(0.6576719741)(-0.135189)(0.977809)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.3826977972 = 0.3529368698 + 1.000000(-0.0297609274)(-1.0000000000)`

:math:`w_2 = 0.3826977972 = 0.3529368698 + 1.000000(-0.0297609274)(-1.0000000000)`

:math:`bias = 0.0231759423 = 0.0529368698 + (1.0000000000)(-0.0297609274)`

Input 2 - Iteration 2
~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.6757655001              -0.6257655001             0.1957912306                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.6757655001)(1 - 0.3242344999)(-0.6257655001) = -0.1371092816`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.8873095894 = 0.9315299320 + 1.000000(-0.1371092816)(0.3225189578)`

:math:`w_2 = 0.8873095894 = 0.9315299320 + 1.000000(-0.1371092816)(0.3225189578)`

:math:`bias = -0.0036023038 = 0.1335069779 + (1.0000000000)(-0.1371092816)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0279071871 = (0.3225189578)(0.6774810422)(-0.137109)(0.931530)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4106049843 = 0.3826977972 + 1.000000(-0.0279071871)(-1.0000000000)`

:math:`w_2 = 0.4106049843 = 0.3826977972 + 1.000000(-0.0279071871)(-1.0000000000)`

:math:`bias = -0.0047312448 = 0.0231759423 + (1.0000000000)(-0.0279071871)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0279071871 = (0.3225189578)(0.6774810422)(-0.137109)(0.931530)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4106049843 = 0.3826977972 + 1.000000(-0.0279071871)(-1.0000000000)`

:math:`w_2 = 0.4106049843 = 0.3826977972 + 1.000000(-0.0279071871)(-1.0000000000)`

:math:`bias = -0.0047312448 = 0.0231759423 + (1.0000000000)(-0.0279071871)`

Input 2 - Iteration 3
~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.6310621774              -0.5810621774             0.1688166270                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.6310621774)(1 - 0.3689378226)(-0.5810621774) = -0.1352844683`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.8461149327 = 0.8873095894 + 1.000000(-0.1352844683)(0.3045039626)`

:math:`w_2 = 0.8461149327 = 0.8873095894 + 1.000000(-0.1352844683)(0.3045039626)`

:math:`bias = -0.1388867721 = -0.0036023038 + (1.0000000000)(-0.1352844683)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0254220590 = (0.3045039626)(0.6954960374)(-0.135284)(0.887310)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4360270433 = 0.4106049843 + 1.000000(-0.0254220590)(-1.0000000000)`

:math:`w_2 = 0.4360270433 = 0.4106049843 + 1.000000(-0.0254220590)(-1.0000000000)`

:math:`bias = -0.0301533038 = -0.0047312448 + (1.0000000000)(-0.0254220590)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0254220590 = (0.3045039626)(0.6954960374)(-0.135284)(0.887310)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4360270433 = 0.4106049843 + 1.000000(-0.0254220590)(-1.0000000000)`

:math:`w_2 = 0.4360270433 = 0.4106049843 + 1.000000(-0.0254220590)(-1.0000000000)`

:math:`bias = -0.0301533038 = -0.0047312448 + (1.0000000000)(-0.0254220590)`

Input 2 - Iteration 4
~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.5864928913              -0.5364928913             0.1439123112                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.5864928913)(1 - 0.4135071087)(-0.5364928913) = -0.1301097086`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.8085656495 = 0.8461149327 + 1.000000(-0.1301097086)(0.2885970893)`

:math:`w_2 = 0.8085656495 = 0.8461149327 + 1.000000(-0.1301097086)(0.2885970893)`

:math:`bias = -0.2689964807 = -0.1388867721 + (1.0000000000)(-0.1301097086)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0226019884 = (0.2885970893)(0.7114029107)(-0.130110)(0.846115)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4586290318 = 0.4360270433 + 1.000000(-0.0226019884)(-1.0000000000)`

:math:`w_2 = 0.4586290318 = 0.4360270433 + 1.000000(-0.0226019884)(-1.0000000000)`

:math:`bias = -0.0527552922 = -0.0301533038 + (1.0000000000)(-0.0226019884)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0226019884 = (0.2885970893)(0.7114029107)(-0.130110)(0.846115)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4586290318 = 0.4360270433 + 1.000000(-0.0226019884)(-1.0000000000)`

:math:`w_2 = 0.4586290318 = 0.4360270433 + 1.000000(-0.0226019884)(-1.0000000000)`

:math:`bias = -0.0527552922 = -0.0301533038 + (1.0000000000)(-0.0226019884)`

Input 2 - Iteration 5
~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.5437669691              -0.4937669691             0.1219029099                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.5437669691)(1 - 0.4562330309)(-0.4937669691) = -0.1224959082`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.7748942389 = 0.8085656495 + 1.000000(-0.1224959082)(0.2748778401)`

:math:`w_2 = 0.7748942389 = 0.8085656495 + 1.000000(-0.1224959082)(0.2748778401)`

:math:`bias = -0.3914923889 = -0.2689964807 + (1.0000000000)(-0.1224959082)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0197418467 = (0.2748778401)(0.7251221599)(-0.122496)(0.808566)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4783708785 = 0.4586290318 + 1.000000(-0.0197418467)(-1.0000000000)`

:math:`w_2 = 0.4783708785 = 0.4586290318 + 1.000000(-0.0197418467)(-1.0000000000)`

:math:`bias = -0.0724971390 = -0.0527552922 + (1.0000000000)(-0.0197418467)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0197418467 = (0.2748778401)(0.7251221599)(-0.122496)(0.808566)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4783708785 = 0.4586290318 + 1.000000(-0.0197418467)(-1.0000000000)`

:math:`w_2 = 0.4783708785 = 0.4586290318 + 1.000000(-0.0197418467)(-1.0000000000)`

:math:`bias = -0.0724971390 = -0.0527552922 + (1.0000000000)(-0.0197418467)`

Input 2 - Iteration 6
~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.5041151686              -0.4541151686             0.1031102932                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.5041151686)(1 - 0.4958848314)(-0.4541151686) = -0.1135211019`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.7450118878 = 0.7748942389 + 1.000000(-0.1135211019)(0.2632316867)`

:math:`w_2 = 0.7450118878 = 0.7748942389 + 1.000000(-0.1135211019)(0.2632316867)`

:math:`bias = -0.5050134907 = -0.3914923889 + (1.0000000000)(-0.1135211019)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0170603578 = (0.2632316867)(0.7367683133)(-0.113521)(0.774894)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4954312364 = 0.4783708785 + 1.000000(-0.0170603578)(-1.0000000000)`

:math:`w_2 = 0.4954312364 = 0.4783708785 + 1.000000(-0.0170603578)(-1.0000000000)`

:math:`bias = -0.0895574968 = -0.0724971390 + (1.0000000000)(-0.0170603578)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0170603578 = (0.2632316867)(0.7367683133)(-0.113521)(0.774894)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.4954312364 = 0.4783708785 + 1.000000(-0.0170603578)(-1.0000000000)`

:math:`w_2 = 0.4954312364 = 0.4783708785 + 1.000000(-0.0170603578)(-1.0000000000)`

:math:`bias = -0.0895574968 = -0.0724971390 + (1.0000000000)(-0.0170603578)`

Input 2 - Iteration 7
~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.4681925346              -0.4181925346             0.0874424980                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.4681925346)(1 - 0.5318074654)(-0.4181925346) = -0.1041250421`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.7186238376 = 0.7450118878 + 1.000000(-0.1041250421)(0.2534265496)`

:math:`w_2 = 0.7186238376 = 0.7450118878 + 1.000000(-0.1041250421)(0.2534265496)`

:math:`bias = -0.6091385328 = -0.5050134907 + (1.0000000000)(-0.1041250421)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0146771943 = (0.2534265496)(0.7465734504)(-0.104125)(0.745012)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5101084307 = 0.4954312364 + 1.000000(-0.0146771943)(-1.0000000000)`

:math:`w_2 = 0.5101084307 = 0.4954312364 + 1.000000(-0.0146771943)(-1.0000000000)`

:math:`bias = -0.1042346912 = -0.0895574968 + (1.0000000000)(-0.0146771943)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0146771943 = (0.2534265496)(0.7465734504)(-0.104125)(0.745012)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5101084307 = 0.4954312364 + 1.000000(-0.0146771943)(-1.0000000000)`

:math:`w_2 = 0.5101084307 = 0.4954312364 + 1.000000(-0.0146771943)(-1.0000000000)`

:math:`bias = -0.1042346912 = -0.0895574968 + (1.0000000000)(-0.0146771943)`

Input 2 - Iteration 8
~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.4361640748              -0.3861640748             0.0745613463                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.4361640748)(1 - 0.5638359252)(-0.3861640748) = -0.0949673903`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.6953391156 = 0.7186238376 + 1.000000(-0.0949673903)(0.2451865002)`

:math:`w_2 = 0.6953391156 = 0.7186238376 + 1.000000(-0.0949673903)(0.2451865002)`

:math:`bias = -0.7041059231 = -0.6091385328 + (1.0000000000)(-0.0949673903)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0126302613 = (0.2451865002)(0.7548134998)(-0.094967)(0.718624)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5227386920 = 0.5101084307 + 1.000000(-0.0126302613)(-1.0000000000)`

:math:`w_2 = 0.5227386920 = 0.5101084307 + 1.000000(-0.0126302613)(-1.0000000000)`

:math:`bias = -0.1168649525 = -0.1042346912 + (1.0000000000)(-0.0126302613)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0126302613 = (0.2451865002)(0.7548134998)(-0.094967)(0.718624)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5227386920 = 0.5101084307 + 1.000000(-0.0126302613)(-1.0000000000)`

:math:`w_2 = 0.5227386920 = 0.5101084307 + 1.000000(-0.0126302613)(-1.0000000000)`

:math:`bias = -0.1168649525 = -0.1042346912 + (1.0000000000)(-0.0126302613)`

Input 2 - Iteration 9
~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.4078675011              -0.3578675011             0.0640345742                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.4078675011)(1 - 0.5921324989)(-0.3578675011) = -0.0864291537`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.6747480671 = 0.6953391156 + 1.000000(-0.0864291537)(0.2382419310)`

:math:`w_2 = 0.6747480671 = 0.6953391156 + 1.000000(-0.0864291537)(0.2382419310)`

:math:`bias = -0.7905350768 = -0.7041059231 + (1.0000000000)(-0.0864291537)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0109066703 = (0.2382419310)(0.7617580690)(-0.086429)(0.695339)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5336453623 = 0.5227386920 + 1.000000(-0.0109066703)(-1.0000000000)`

:math:`w_2 = 0.5336453623 = 0.5227386920 + 1.000000(-0.0109066703)(-1.0000000000)`

:math:`bias = -0.1277716228 = -0.1168649525 + (1.0000000000)(-0.0109066703)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0109066703 = (0.2382419310)(0.7617580690)(-0.086429)(0.695339)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5336453623 = 0.5227386920 + 1.000000(-0.0109066703)(-1.0000000000)`

:math:`w_2 = 0.5336453623 = 0.5227386920 + 1.000000(-0.0109066703)(-1.0000000000)`

:math:`bias = -0.1277716228 = -0.1168649525 + (1.0000000000)(-0.0109066703)`

Input 2 - Iteration 10
~~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.3829671086              -0.3329671086             0.0554335477                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.3829671086)(1 - 0.6170328914)(-0.3329671086) = -0.0786812273`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.6564661093 = 0.6747480671 + 1.000000(-0.0786812273)(0.2323547618)`

:math:`w_2 = 0.6564661093 = 0.6747480671 + 1.000000(-0.0786812273)(0.2323547618)`

:math:`bias = -0.8692163042 = -0.7905350768 + (1.0000000000)(-0.0786812273)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0094694534 = (0.2323547618)(0.7676452382)(-0.078681)(0.674748)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5431148157 = 0.5336453623 + 1.000000(-0.0094694534)(-1.0000000000)`

:math:`w_2 = 0.5431148157 = 0.5336453623 + 1.000000(-0.0094694534)(-1.0000000000)`

:math:`bias = -0.1372410762 = -0.1277716228 + (1.0000000000)(-0.0094694534)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0094694534 = (0.2323547618)(0.7676452382)(-0.078681)(0.674748)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5431148157 = 0.5336453623 + 1.000000(-0.0094694534)(-1.0000000000)`

:math:`w_2 = 0.5431148157 = 0.5336453623 + 1.000000(-0.0094694534)(-1.0000000000)`

:math:`bias = -0.1372410762 = -0.1277716228 + (1.0000000000)(-0.0094694534)`

Input 2 - Iteration 11
~~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.3610632421              -0.3110632421             0.0483801703                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.3610632421)(1 - 0.6389367579)(-0.3110632421) = -0.0717612253`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.6401528992 = 0.6564661093 + 1.000000(-0.0717612253)(0.2273262473)`

:math:`w_2 = 0.6401528992 = 0.6564661093 + 1.000000(-0.0717612253)(0.2273262473)`

:math:`bias = -0.9409775295 = -0.8692163042 + (1.0000000000)(-0.0717612253)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0082746169 = (0.2273262473)(0.7726737527)(-0.071761)(0.656466)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5513894327 = 0.5431148157 + 1.000000(-0.0082746169)(-1.0000000000)`

:math:`w_2 = 0.5513894327 = 0.5431148157 + 1.000000(-0.0082746169)(-1.0000000000)`

:math:`bias = -0.1455156932 = -0.1372410762 + (1.0000000000)(-0.0082746169)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0082746169 = (0.2273262473)(0.7726737527)(-0.071761)(0.656466)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5513894327 = 0.5431148157 + 1.000000(-0.0082746169)(-1.0000000000)`

:math:`w_2 = 0.5513894327 = 0.5431148157 + 1.000000(-0.0082746169)(-1.0000000000)`

:math:`bias = -0.1455156932 = -0.1372410762 + (1.0000000000)(-0.0082746169)`

Input 2 - Iteration 12
~~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.3417567989              -0.2917567989             0.0425610149                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.3417567989)(1 - 0.6582432011)(-0.2917567989) = -0.0656333438`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.6255169590 = 0.6401528992 + 1.000000(-0.0656333438)(0.2229954985)`

:math:`w_2 = 0.6255169590 = 0.6401528992 + 1.000000(-0.0656333438)(0.2229954985)`

:math:`bias = -1.0066108732 = -0.9409775295 + (1.0000000000)(-0.0656333438)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0072799413 = (0.2229954985)(0.7770045015)(-0.065633)(0.640153)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5586693740 = 0.5513894327 + 1.000000(-0.0072799413)(-1.0000000000)`

:math:`w_2 = 0.5586693740 = 0.5513894327 + 1.000000(-0.0072799413)(-1.0000000000)`

:math:`bias = -0.1527956345 = -0.1455156932 + (1.0000000000)(-0.0072799413)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0072799413 = (0.2229954985)(0.7770045015)(-0.065633)(0.640153)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5586693740 = 0.5513894327 + 1.000000(-0.0072799413)(-1.0000000000)`

:math:`w_2 = 0.5586693740 = 0.5513894327 + 1.000000(-0.0072799413)(-1.0000000000)`

:math:`bias = -0.1527956345 = -0.1455156932 + (1.0000000000)(-0.0072799413)`

Input 2 - Iteration 13
~~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.3246811355              -0.2746811355             0.0377248631                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.3246811355)(1 - 0.6753188645)(-0.2746811355) = -0.0602274911`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.6123130302 = 0.6255169590 + 1.000000(-0.0602274911)(0.2192342489)`

:math:`w_2 = 0.6123130302 = 0.6255169590 + 1.000000(-0.0602274911)(0.2192342489)`

:math:`bias = -1.0668383643 = -1.0066108732 + (1.0000000000)(-0.0602274911)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0064485640 = (0.2192342489)(0.7807657511)(-0.060227)(0.625517)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5651179380 = 0.5586693740 + 1.000000(-0.0064485640)(-1.0000000000)`

:math:`w_2 = 0.5651179380 = 0.5586693740 + 1.000000(-0.0064485640)(-1.0000000000)`

:math:`bias = -0.1592441985 = -0.1527956345 + (1.0000000000)(-0.0064485640)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0064485640 = (0.2192342489)(0.7807657511)(-0.060227)(0.625517)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5651179380 = 0.5586693740 + 1.000000(-0.0064485640)(-1.0000000000)`

:math:`w_2 = 0.5651179380 = 0.5586693740 + 1.000000(-0.0064485640)(-1.0000000000)`

:math:`bias = -0.1592441985 = -0.1527956345 + (1.0000000000)(-0.0064485640)`

Input 2 - Iteration 14
~~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.3095141649              -0.2595141649             0.0336738009                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.3095141649)(1 - 0.6904858351)(-0.2595141649) = -0.0554621078`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.6003364968 = 0.6123130302 + 1.000000(-0.0554621078)(0.2159408266)`

:math:`w_2 = 0.6003364968 = 0.6123130302 + 1.000000(-0.0554621078)(0.2159408266)`

:math:`bias = -1.1223004721 = -1.0668383643 + (1.0000000000)(-0.0554621078)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0057498097 = (0.2159408266)(0.7840591734)(-0.055462)(0.612313)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5708677477 = 0.5651179380 + 1.000000(-0.0057498097)(-1.0000000000)`

:math:`w_2 = 0.5708677477 = 0.5651179380 + 1.000000(-0.0057498097)(-1.0000000000)`

:math:`bias = -0.1649940082 = -0.1592441985 + (1.0000000000)(-0.0057498097)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0057498097 = (0.2159408266)(0.7840591734)(-0.055462)(0.612313)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5708677477 = 0.5651179380 + 1.000000(-0.0057498097)(-1.0000000000)`

:math:`w_2 = 0.5708677477 = 0.5651179380 + 1.000000(-0.0057498097)(-1.0000000000)`

:math:`bias = -0.1649940082 = -0.1592441985 + (1.0000000000)(-0.0057498097)`

Input 2 - Iteration 15
~~~~~~~~~~~~~~~~~~~~~~

Feed Forward Epoch
^^^^^^^^^^^^^^^^^^

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.2959798618              -0.2459798618             0.0302530462                       
=========================== ========================= ========================= ==================================

Back-Propagation Phase
^^^^^^^^^^^^^^^^^^^^^^

Output Layer Delta
<<<<<<<<<<<<<<<<<<

:math:`\delta = (0.2959798618)(1 - 0.7040201382)(-0.2459798618) = -0.0512562463`

Output Layer Weights
<<<<<<<<<<<<<<<<<<<<

:math:`w_1 = 0.5894171413 = 0.6003364968 + 1.000000(-0.0512562463)(0.2130346311)`

:math:`w_2 = 0.5894171413 = 0.6003364968 + 1.000000(-0.0512562463)(0.2130346311)`

:math:`bias = -1.1735567184 = -1.1223004721 + (1.0000000000)(-0.0512562463)`

Hidden Layer 1
<<<<<<<<<<<<<<

Hidden Layer 1 - Peceptron 1 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0051587844 = (0.2130346311)(0.7869653689)(-0.051256)(0.600336)`

Hidden Layer 1 - Peceptron 1 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5760265321 = 0.5708677477 + 1.000000(-0.0051587844)(-1.0000000000)`

:math:`w_2 = 0.5760265321 = 0.5708677477 + 1.000000(-0.0051587844)(-1.0000000000)`

:math:`bias = -0.1701527926 = -0.1649940082 + (1.0000000000)(-0.0051587844)`

Hidden Layer 1 - Peceptron 2 Delta
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`\delta = -0.0051587844 = (0.2130346311)(0.7869653689)(-0.051256)(0.600336)`

Hidden Layer 1 - Peceptron 2 Weights
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

:math:`w_1 = 0.5760265321 = 0.5708677477 + 1.000000(-0.0051587844)(-1.0000000000)`

:math:`w_2 = 0.5760265321 = 0.5708677477 + 1.000000(-0.0051587844)(-1.0000000000)`

:math:`bias = -0.1701527926 = -0.1649940082 + (1.0000000000)(-0.0051587844)`


.. _successive-training-input-2-15-rounds:

Result of 15 Iterations for Input 2
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.2838448109              -0.2338448109             0.0273416978                       
=========================== ========================= ========================= ==================================


.. _successive-training-final:

Method 2 - Final Network
~~~~~~~~~~~~~~~~~~~~~~~~

.. graphviz::

    digraph network{
    rankdir=LR;
    node [shape=plaintext,width=0.25,label=<x<SUB>1</SUB>>]; x_1;
    node [shape=plaintext,width=0.25,label=<x<SUB>2</SUB>>]; x_2;
    node [shape=square,width=.25,fillcolor=black,style=filled,label=""]; input_0, input_1
    node [shape=circle,width=.5,fillcolor=white,label="-0.170153"]; h_0_0;
    node [shape=circle,width=.5,fillcolor=white,label="-0.170153"]; h_0_1;
    node [shape=circle,width=.5,fillcolor=white,label="-1.173557"]; o_0;
    node [shape=circle,width=.5,style=invisible,label=""]; output;
    
    
    x_1 -> input_0;
    x_2 -> input_1;
    input_0 -> h_0_0 [label="0.576027"];
    input_1 -> h_0_0 [label="0.576027"];
    input_0 -> h_0_1 [label="0.576027"];
    input_1 -> h_0_1 [label="0.576027"];
    h_0_0 -> o_0 [label="0.589417"];
    h_0_1 -> o_0 [label="0.589417"];
    o_0 -> output [label="Output"];
    }
    


.. _successive-validation-test:

Successive Training Final Feed Forward Epoch Test
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

These are the results after 15 iterations of training as described above.

Feed forward with inputs: (1, 1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.9000000000                0.4216576338              0.4783423662              0.1144057096                       
=========================== ========================= ========================= ==================================

Feed forward with inputs: (-1, -1)

=========================== ========================= ========================= ==================================
Expected Output :math:`(d)` Actual Output :math:`(y)` error :math:`(e = d - y)` Error :math:`(E = \frac{1}{2}e^2)`
=========================== ========================= ========================= ==================================
0.0500000000                0.2838448109              -0.2338448109             0.0273416978                       
=========================== ========================= ========================= ==================================


.. include:: homework5_analysis.rst

